# MMDetectionæ•´ä½“æ„å»ºæµç¨‹æ€æƒ³

# Preface
all referenceï¼šhttps://zhuanlan.zhihu.com/p/337375549
æœ¬æ–‡å…¨ç¯‡ç…§æŠ„ã€‚

ç›®å‰æµç¨‹æ€æƒ³éƒ½æœ‰ä»¥ä¸‹æµç¨‹åˆ’åˆ†ï¼š
![æ•´ä½“æ„å»ºæµç¨‹](https://pic1.zhimg.com/80/v2-7ecc8e5e19c59a3e6682c5e3cdc34918_720w.jpg)

è®­ç»ƒæ ¸å¿ƒç»„ä»¶ä¸€èˆ¬åŒ…æ‹¬9ä¸ªï¼š
1. ç‰¹å¾æå–ï¼Œbackboneå±‚ï¼Œä¾‹å¦‚ResNetå±‚
2. ä½†å°ºåº¦æˆ–è€…å¤šå°ºåº¦ç‰¹å¾å›¾è¾“å…¥åˆ°neckæ¨¡å—ä¸­è¿›è¡Œç‰¹å¾èåˆæˆ–è€…å¢å¼ºï¼Œå…¸å‹çš„neckå°±æ˜¯FPNã€‚
3. ä¸€èˆ¬å¤šå°ºåº¦ç‰¹å¾æœ€åéƒ½ä¼šè¾“å…¥åˆ°headéƒ¨åˆ†ä¸€èˆ¬åŒ…æ‹¬åˆ†ç±»å’Œå›å½’åˆ†æ”¯è¾“å‡ºã€‚
4. æ•´ä¸ªç½‘ç»œæ„å»ºé˜¶æ®µéƒ½å¯ä»¥å¼•å…¥ä¸€äº›å³æ’å³ç”¨å¢å¼ºç®—å­æ¥å¢åŠ æå–èƒ½åŠ›ï¼Œä¾‹å¦‚SPPï¼ŒDCNç­‰
5. ç›®æ ‡æ£€æµ‹headè¾“å‡ºä¸€èˆ¬æ˜¯ç‰¹å¾å›¾ï¼Œå¯¹äºåˆ†ç±»ä»»åŠ¡å­˜åœ¨ä¸¥é‡çš„æ­£è´Ÿæ ·æœ¬ä¸å¹³è¡¡ï¼Œå¯ä»¥é€šè¿‡æ­£è´Ÿæ ·æœ¬å±æ€§åˆ†é…å’Œé‡‡æ ·æ§åˆ¶
6. ä¸ºäº†æ–¹ä¾¿æ”¶æ•›å’Œå¹³è¡¡å¤šåˆ†æ”¯ï¼Œä¸€èˆ¬éƒ½ä¼šå¯¹gt bboxè¿›è¡Œç¼–ç ã€‚
7. æœ€åä¸€æ­¥æ˜¯è®¡ç®—åˆ†ç±»å’Œå›å½’lossï¼Œè¿›è¡Œè®­ç»ƒ
8. è®­ç»ƒè¿‡ç¨‹ä¸­ä¹ŸåŒ…æ‹¬éå¸¸å¤šçš„trick,ä¾‹å¦‚ä¼˜åŒ–å™¨é€‰æ‹©ï¼Œå‚æ•°è°ƒèŠ‚ç­‰ã€‚

ä½†æ˜¯ä»¥ä¸Š9ä¸ªç»„ä»¶ä¸æ˜¯æ¯ä¸€ä¸ªç®—æ³•éƒ½éœ€è¦çš„ã€‚


# Backbone

![](https://pic2.zhimg.com/80/v2-cdee2bd9f289d650ddbcbd748c4be0f9_720w.jpg)

backboneä½œç”¨ä¸»è¦æ˜¯ç‰¹å¾æå–ï¼Œç›®å‰MMDetectiohnå·²ç»é›†æˆäº†å¤§éƒ¨åˆ†éª¨æ¶ç½‘ç»œï¼Œå¯ä»¥çœ‹ä¸€ä¸‹`mmdet/models/backbones`
å¯ä»¥çœ‹åˆ°æœ‰ï¼š
```python
__all__ = [
    'RegNet', 'ResNet', 'ResNetV1d', 'ResNeXt', 'SSDVGG', 'HRNet',
    'MobileNetV2', 'Res2Net', 'HourglassNet', 'DetectoRS_ResNet',
    'DetectoRS_ResNeXt', 'Darknet', 'ResNeSt', 'TridentResNet', 'CSPDarknet',
    'SwinTransformer', 'PyramidVisionTransformer', 'PyramidVisionTransformerV2'
]
```
æœ€å¸¸ç”¨çš„è¿˜æ˜¯ResNetç³»åˆ—ï¼ŒResNetV1dç³»åˆ—å’ŒRes2Netç³»åˆ—ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦å¯¹éª¨æ¶è¿›è¡Œæ‰©å±•ï¼Œæˆ‘ä»¬å¯ä»¥ç»§æ‰¿ä¸Šè¿°ç½‘ç»œï¼Œç„¶åé€šè¿‡æ³¨å†Œå™¨æœºåˆ¶æ³¨å†Œä½¿ç”¨ã€‚ä¸€ä¸ªå…¸å‹çš„ç”¨æ³•æ˜¯ï¼š
```python
# éª¨æ¶çš„é¢„è®­ç»ƒæƒé‡è·¯å¾„
pretrained='torchvision://resnet50',
backbone=dict(
    type='ResNet', # éª¨æ¶ç±»åï¼Œåé¢çš„å‚æ•°éƒ½æ˜¯è¯¥ç±»çš„åˆå§‹åŒ–å‚æ•°
    depth=50,
    num_stages=4,
    out_indices=(0, 1, 2, 3),
    frozen_stages=1,
    norm_cfg=dict(type='BN', requires_grad=True), 
    norm_eval=True,
    style='pytorch'),
```

é€šè¿‡MMCVçš„æ³¨å†Œå™¨æœºåˆ¶ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡dictå½¢å¼é…ç½®æ¥å®ä¾‹åŒ–ä»»ä½•å·²ç»æ³¨å†Œçš„ç±»ï¼Œéå¸¸æ–¹ä¾¿å’Œçµæ´»ã€‚

# Neck
![](https://pic1.zhimg.com/80/v2-f0975c00a32fa03a80860f9c09234bbc_720w.jpg)

neckå¯ä»¥è®¤ä¸ºæ˜¯backboneå’Œheadçš„è¿æ¥å±‚ï¼Œä¸»è¦è´Ÿè´£å¯¹backboneçš„ç‰¹å¾è¿›è¡Œé«˜æ•ˆèåˆå’Œå¢å¼ºï¼Œèƒ½å¤Ÿå¯¹è¾“å…¥çš„ä½†å°ºåº¦æˆ–è€…å¤šå°ºåº¦ç‰¹å¾è¿›è¡Œèåˆã€å¢å¼ºè¾“å‡ºç­‰ã€‚æˆ‘ä»¬å¯ä»¥çœ‹ä¸€ä¸‹æ–‡ä»¶`mmdet/models/necks`
```python
__all__ = [
    'FPN', 'BFP', 'ChannelMapper', 'HRFPN', 'NASFPN', 'FPN_CARAFE', 'PAFPN',
    'NASFCOS_FPN', 'RFP', 'YOLOV3Neck', 'FPG', 'DilatedEncoder',
    'CTResNetNeck', 'SSDNeck', 'YOLOXPAFPN'
]

```
è¿™ä¸ªæœ€å¸¸ç”¨çš„åº”è¯¥æ˜¯FPNï¼Œä¸€ä¸ªå…¸å‹çš„ç”¨æ³•ä¸ºï¼š
```python
neck=dict(
    type='FPN',
    in_channels=[256, 512, 1024, 2048], # éª¨æ¶å¤šå°ºåº¦ç‰¹å¾å›¾è¾“å‡ºé€šé“
    out_channels=256, # å¢å¼ºåé€šé“è¾“å‡º
    num_outs=5), # è¾“å‡ºnum_outsä¸ªå¤šå°ºåº¦ç‰¹å¾å›¾
```

# Head
![](https://pic2.zhimg.com/80/v2-fdd9a6232e62c75b143153dab8ba9bc1_720w.jpg)

ç›®æ ‡æ£€æµ‹ç®—æ³•è¾“å‡ºä¸€èˆ¬åŒ…æ‹¬åˆ†ç±»å’Œç‹‚åæ ‡å›å½’ä¸¤ä¸ªåˆ†æ”¯ï¼Œä¸åŒç®—æ³•headæ¨¡å—å¤æ‚ç¨‹åº¦ä¸ä¸€æ ·ï¼Œçµæ´»åº¦æ¯”è¾ƒé«˜ã€‚åœ¨ç½‘ç»œæ„å»ºæ–¹é¢ï¼Œç†è§£ç›®æ ‡æ£€æµ‹ç®—æ³•ä¸»è¦æ˜¯è¦ç†è§£headæ¨¡å—ã€‚
MMDetectioné‡headæ¨¡å—åˆåˆ’åˆ†ä¸ºtwo-stageæ‰€éœ€çš„ROIHEADå’Œone-stageæ‰€éœ€çš„DenseHead,ä¹Ÿå°±æ˜¯è¯´æ‰€æœ‰çš„one-stageç®—æ³•çš„headæ¨¡å—éƒ½åœ¨`mmdet/models/dense_heads`ä¸­ï¼Œè€Œtwo-stageç®—æ³•è¿˜åŒ…æ‹¬é¢å¤–çš„`mmdet/models/roi_heads`.




---
title: mmdet && project of fenghuo
author: é€¯æ¶¦é›¨
top: false
cover: false
toc: true
mathjax: false
date: 2021-11-09 19:22:50
img:
coverImg:
keywords:
password:
summary: 
  æœ¬åšå®¢è®°å½•çƒ½ç«é¡¹ç›®æœ¬äººçš„åšé¡¹ç›®çš„æŠ€æœ¯è¿‡ç¨‹ã€‚
tags:
 - æ·±åº¦å­¦ä¹ 
 - é¡¹ç›®
 - çƒ½ç«é›†å›¢
categories:
 - æ·±åº¦å­¦ä¹ 
---





# Preface

> 2021.11.9æ—¥æ›´æ–°ï¼š

æœ¬åšå®¢è®°å½•çƒ½ç«é¡¹ç›®æœ¬äººçš„åšé¡¹ç›®çš„æŠ€æœ¯è¿‡ç¨‹ã€‚é¦–å…ˆ------æˆ‘ä¸ä¼šåˆ†å‰²å‘¢è¿˜ğŸ˜£ğŸ˜£ğŸ˜£ï¼Œæˆ‘å°±å¤§æ¦‚çŸ¥é“åˆ†å‰²æ˜¯ä»€ä¹ˆå¦å¤–å°±æ˜¯æ•°æ®é›†å¤§è‡´å½¢å¼â€¦â€¦ï¼ˆ~~è™½ç„¶ç›®å‰æ¥çœ‹ä¹Ÿå¤Ÿäº†â€¦â€¦~~ï¼‰

è¿™å°±æ˜¯"å¹²ä¸­å­¦"å˜›ğŸ˜­ğŸ˜­ã€‚

å¹¸äºçš„æ˜¯ï¼Œä¹‹å‰çœ‹çš„è®¸å¤šå®˜æ–¹æ–‡æ¡£æˆ‘éƒ½è®°å½•äº†ç›¸å…³çš„è¿‡ç¨‹ï¼Œä¸éœ€è¦é‡å¤çœ‹æ–‡æ¡£äº†ï¼Œè€Œä¸”ã€‚ä¸€ä¸ªæ›´å¥½çš„æ¶ˆæ¯å°±æ˜¯æˆ‘å½“æ—¶çœ‹çš„å®˜æ–¹æ–‡æ¡£å‡ ä¹éƒ½æ˜¯å…³äºMaskRCNNçš„ï¼Œæˆ‘å®é™…ä¸Šå¯¹è¿™äº›ä¸œè¥¿çš„æµ‹è¯•è®­ç»ƒçš„å¾ˆå¤šæµç¨‹éå¸¸æ¸…æ¥šäº†ï¼ˆ~~åªæ˜¯ä¸€éƒ¨åˆ†ï¼Œä¸€å°éƒ¨åˆ†~~ï¼‰ï¼Œè¿™å°±ä¸ºæˆ‘è™½ç„¶ä¸ç†Ÿæ‚‰ã€ä¸å¤ªä¼šMaskRCNNä½†æ˜¯ä¸ä¼šå¯¹æˆ‘è®­ç»ƒã€å¯¹æˆ‘æ¨ç†ç›¸å…³æ¨¡å‹äº§ç”Ÿä¸€äº›å¾ˆå¤§çš„éšœç¢ï¼Œæˆ‘æˆ–è®¸åªéœ€è¦å°±æƒ³åœ¨åšæ£€æµ‹ä¸€æ ·æ¥åšè¿™ä¸€ä»¶äº‹å°±å¥½äº†ã€‚å½“ç„¶è¾“å…¥å’Œè¾“å‡ºè¿˜æ˜¯è¦æˆ‘è‡ªå·±æ¥æå®šçš„ï¼Œè¿™ä¹Ÿæ˜¯æœ€ä¸å¥½å¼„çš„ä¸€éƒ¨åˆ†ã€‚

ç”±äºæœ¬æœˆæœˆæœ«ä¼šæœ‰ä¸¤åœºæ¯”è¾ƒé‡è¦çš„è€ƒè¯•ï¼Œæ‰€ä»¥æœ€å¥½æˆ‘èƒ½åœ¨æœ¬å‘¨å¤§è‡´å†™å‡ºä¸€éƒ¨åˆ†ä»£ç ç„¶ådebugä¸€äº›ä¸œè¥¿ï¼Œè¿™ä¸¤å‘¨å¯ä»¥é€‚å½“å¤šå‚åŠ ä¸€ä¸‹é¡¹ç›®ç„¶ååˆ°æœ¬æœˆåä¸€å‘¨å¼€å§‹å‡†å¤‡è€ƒè¯•ã€‚

# 2021.11.9æ—¥æ™šæ›´æ–°

å·®ä¸å¤šç¡®å®šè®¡åˆ’ä¹‹åï¼Œè¿™ä¸€æ™šä¸Šè¿˜æ˜¯å…ˆçœ‹çœ‹æˆ‘ä¹‹å‰çš„æ‰€æœ‰å…³äºMMDetectionçš„åšå®¢ï¼Œå¯¹äºè®­ç»ƒå’Œæµ‹è¯•ä»¥åŠæ•°æ®é›†é‡æ–°ç†Ÿæ‚‰æ•´åˆä¸€ä¸‹ã€‚

**Note**: MMDetection only supports evaluating mask AP of dataset in COCO format for now. So for instance segmentation task users should convert the data into coco format.

## Config
### dataset prepare

è¿™é‡Œæˆ‘åˆæ­¥æ‰“ç®—æ ¹æ®æˆ‘ä»¬çš„jsonæ–‡ä»¶å†™ä¸€ä¸ªè½¬åŒ–ä¸ºCOCOæ•°æ®é›†çš„`.py`æ–‡ä»¶ï¼Œå› ä¸ºç»„é•¿æ¨èçš„å†™ä¸€ä¸ªdataloaderè¿™ç§æ–¹å¼æˆ‘ç›®å‰æ²¡æœ‰å¤ªæ˜ç™½ï¼Œåæ­£ä¸ç®¡é»‘çŒ«ç™½çŒ«,å…ˆå†™å‡ºæ¥èƒ½è·‘å°±è¡ŒğŸ˜ã€‚


COCOæ•°æ®é›†å¤§æ¦‚é•¿è¿™ä¸ªæ ·å­ï¼š
```python
{
    "images": [image],
    "annotations": [annotation],
    "categories": [category]
}


image = {
    "id": int,
    "width": int,
    "height": int,
    "file_name": str,
}

annotation = {
    "id": int,
    "image_id": int,
    "category_id": int,
    "segmentation": RLE or [polygon],
    "area": float,
    "bbox": [x,y,width,height],
    "iscrowd": 0 or 1,
}

categories = [{
    "id": int,
    "name": str,
    "supercategory": str,
}]
```
å½“æ—¶çœ‹å®˜ç½‘åå†™çš„åšå®¢å½“æ—¶ç¬¬ä¸€æ­¥å°±æ˜¯è½¬åŒ–ä¸€ä¸‹æ•°æ®é›†ï¼Œå½“æ—¶å®˜ç½‘ä¸“é—¨æä¾›äº†ä¸€ä¸ªBallonæ•°æ®é›†ï¼Œä¹Ÿæ˜¯äºŒåˆ†ç±»çš„æ•°æ®é›†ï¼Œå½“æ—¶æ•°æ®é›†çš„æ ¼å¼ç¡®å®ä¸æ˜¯éå¸¸åˆç†çœ‹ç€ï¼Œåé˜¿é‡Œç»è¿‡è½¬åŒ–ä¹‹åå˜æˆäº†COCOçš„æ ‡å‡†æ ¼å¼ï¼Œæˆ‘ä»¬è¿™é‡Œé‡æ–°æ¥çœ‹ä¸€ä¸‹,å¸å–ä¸Šæ¬¡çš„æ•™è®­ï¼Œè¿™é‡Œé€‰æ‹©åˆ†å±‚æ¥çœ‹ç»“æ„ï¼š
* ç¬¬ä¸€å±‚ç»“æ„ï¼š 
[![](https://s6.jpg.cm/2021/11/09/I967LC.png)](https://imagelol.com/image/I967LC)
å¤§ç»“æ„å°±æ˜¯å›¾åƒéƒ½æœ‰ä»€ä¹ˆï¼Œç„¶åæ ‡è®°éƒ½æ˜¯ä»€ä¹ˆï¼Œç„¶åæ˜¯åˆ†ç±»çš„ç±»åˆ«éƒ½æœ‰ä»€ä¹ˆ.æ¥ä¸‹æ¥æ·±å…¥çœ‹ï¼š
* ç¬¬äºŒå±‚ç»“æ„ä¹‹`images`
[![](https://s6.jpg.cm/2021/11/09/I96d4R.png)](https://imagelol.com/image/I96d4R)

`images`ä¸»è¦è®°å½•çš„å°±æ˜¯å›¾ç‰‡çš„ä¸€ä¸ªidsè¿˜æœ‰é«˜å®½ï¼Œè¿™ä¸ªé«˜å®½è¿˜æ˜¯è›®é‡è¦çš„ï¼Œä»¥åŠæ–‡ä»¶åã€‚

* ç¬¬äºŒå±‚ç»“æ„ä¹‹`annotations`
[![](https://s6.jpg.cm/2021/11/09/I96eDz.png)](https://imagelol.com/image/I96eDz)
è¯¥å±‚å°±æ˜¯æˆ‘ä»¬çš„åˆ†ç±»category_idå’Œæ¡†bboxè¿˜æœ‰åˆ†å‰²æ•°æ®segmentationçš„ç»“æ„äº†ã€‚category_idæ˜¯ç±»åˆ«çš„ç§ç±»æ•°ï¼Œbboxæ˜¯æ£€æµ‹æ¡†ï¼Œsegmentationæ˜¯åˆ†å‰²çš„æ•°æ®æ ‡æ³¨ã€‚å…¶ä»–çš„æ˜¯å’Œä¸Šé¢çš„ä¸€ä¸€å¯¹åº”çš„ï¼ˆ~~æ¯”å¦‚è¯´image_idè¡¨ç¤ºè¯¥æ ‡æ³¨å±äºé‚£ä¸€å¼ å›¾ç‰‡â€¦â€¦~~ï¼‰ï¼Œè¿˜æœ‰ä¸€äº›ä¸è¯´äº†ï¼Œä¸æ˜¯éå¸¸é‡è¦ã€‚
çœ‹ä¸‹å®Œæ•´çš„åŒ…å«å…·ä½“bboxå’Œsegmentationæ•°æ®çš„å›¾ï¼š
[![](https://s6.jpg.cm/2021/11/09/I96U2p.png)](https://imagelol.com/image/I96U2p)

* ç¬¬äºŒå±‚ç»“æ„ä¹‹`categories`:
[![](https://s6.jpg.cm/2021/11/09/I96Y9W.png)](https://imagelol.com/image/I96Y9W)

ç”±äºè¿™ä¸ªæ•°æ®é›†éå¸¸ç®€å•,å°±æ˜¯ä¸€ä¸ªå…³äºballoonçš„æ£€æµ‹åˆ†å‰²ä»»åŠ¡,æ‰€ä»¥ç±»åˆ«åªæœ‰ä¸€ä¸ª,ç›¸å¯¹è€Œè¨€è¿˜æŒºå¥½.
~~æˆ‘çªç„¶èœœæ±è‡ªä¿¡,æˆ‘ä»¬çš„æ•°æ®ä¹Ÿæ˜¯åˆæ­¥åªæœ‰ä¸€ä¸ªæ¡†è®©æˆ‘ä»¬æ£€æµ‹,æˆ‘æ€ä¹ˆè§‰å¾—æˆ‘åˆè¡Œäº†~~

å¥½æ»´,æ•°æ®é›†å¤§æ¦‚å°±æ˜¯è¿™æ ·!æˆ‘ä»¬ç»ˆäºå¯ä»¥æ¥çœ‹ä¸€ä¸‹å…³äºConfigç›¸å…³çš„æ–‡ä»¶äº†.

### config

æˆ‘è‡ªè®¤ä¸ºæˆ‘å½“æ—¶å†™å¾—å…³äºConfigçš„è§£é‡Šå·²ç»å¤Ÿè¯¦ç»†äº†ç›´åˆ°æˆ‘åˆçœ‹äº†ä¸€éç›¸å…³çš„[å®˜æ–¹æ–‡æ¡£](https://mmdetection.readthedocs.io/en/latest/tutorials/config.html),å‘ç°å½“æ—¶è§£é‡Šçš„æ¼æ´è¿˜æ˜¯éå¸¸å¤š,æ‰€ä»¥åœ¨è¿™é‡Œå¤šå†™ä¸€ç‚¹.

> We incorporate modular and inheritance design into our config system, which is convenient to conduct various experiments. If you wish to inspect the config file, you may run `python tools/misc/print_config.py /PATH/TO/CONFIG` to see the complete config.

æ­£å¦‚ä¸Šé¢æˆ‘ä»¬å¯ä»¥é€šè¿‡`python tools/misc/print_config.py /PATH/TO/CONFIG` å‘½ä»¤æ¥å¯¹æˆ‘ä»¬æƒ³è¦äº†è§£çš„configæ–‡ä»¶æ¥çœ‹ä»–ä»¬ç›¸å…³çš„å…·ä½“é…ç½®.~~äºæˆ‘å½“æ—¶è¿˜ä¸“é—¨å†™äº†ä¸ªç›¸å…³çš„æ‰“å°é…ç½®ä»£ç ...~~

æŠ„ä¸€ä¸‹æˆ‘è‡ªå·±çš„blog:
> æˆ‘ä»¬çš„configéœ€è¦æ”¾åˆ°`configs/balloon/`ç›®å½•ä¸‹å¹¶ä¸”å‘½åä¸ºï¼š`mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py`
>
> å…³äºè¿™ä¹ˆä¸€ä¸ªåå­—ï¼Œä¸ºä»€ä¹ˆè¿™ä¹ˆå¤æ‚æ˜¯æœ‰åŸå› çš„ï¼Œå‚è§è¿™é‡Œ:https://mmdetection.readthedocs.io/zh_CN/v2.18.0/tutorials/config.html#id4

å½“æ—¶çš„æˆ‘ä¹ŸçœŸæ˜¯å¤Ÿè¾›è‹¦,å®˜ç½‘ç»™çš„æŒºå¤šä¸œè¥¿éƒ½æœ‰é—®é¢˜,æˆ‘å½“æ—¶å°±è‡ªå·±ä¿®æ”¹äº†è®¸å¤šä¸œè¥¿,æ€»ç®—è®©æˆ‘ä»¬çš„balloon.pyæˆåŠŸè¿è¡Œäº†:
```python
# The new config inherits a base config to highlight the necessary modification
_base_ = '../mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'

# We also need to change the num_classes in head to match the dataset's annotation
model = dict(
    roi_head=dict(
        bbox_head=dict(num_classes=1),
        mask_head=dict(num_classes=1)))

# Modify dataset related settings
dataset_type = 'COCODataset'
classes = ('balloon',)
data = dict(
    train=dict(
        img_prefix='/home/lry/projects/mmdetection/data/balloon/train/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/balloon/train/annotation_coco.json'),
    val=dict(
        img_prefix='/home/lry/projects/mmdetection/data/balloon/val/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/balloon/val/annotation_coco.json'),
    test=dict(
        img_prefix='/home/lry/projects/mmdetection/data/balloon/val/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/balloon/val/annotation_coco.json'))

# We can use the pre-trained Mask RCNN model to obtain higher performance
# load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'
load_from = 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'
```

å½“æ—¶å†™é‚£ç¯‡åšæ–‡[practice mmdet(Customized datasets)](https://lry89757.github.io/2021/10/12/practice-mmdet-customized-datasets/)çš„æ—¶å€™,è¿˜æ²¡æœ‰å½»åº•è¯»æºç è¿›è¡Œç›¸å…³çš„æº¯æº,è€Œåœ¨æˆ‘æº¯æºä»£ç [Code Trace of mmdetection](https://lry89757.github.io/2021/10/16/code-trace-of-mmdetection/)ä¹‹å,å¯¹æ•´ä¸ªå·¥ç¨‹çš„ç†è§£ä¸Šå‡äº†ä¸€ä¸ªå±‚æ¬¡,ä¸å¾—ä¸è¯´è¿˜çœŸæ˜¯å¤Ÿå¯ä»¥çš„,è¿˜æ˜¯å­¦å¥½ç›¸å…³çš„æ–‡ä»¶ã€è¯»æ‡‚æºç æ‰ç®—çœŸæ­£ç†è§£äº†å¾ˆå¤šä¸œè¥¿. è€Œå°½ç®¡è¯»äº†éƒ¨åˆ†æºç ä½†è¿˜æ˜¯ä¸çŸ¥å…¨å±€,æ­£æ˜¯å½“æˆ‘çœ‹äº†çŸ¥ä¹å®˜æ–¹å†™å¾—æ•´ä½“æ¡†æ¶åæ‰æ›´åŠ å…¨å±€äº†è§£äº†æœ‰å…³çš„ç»“æ„.å¯¹äºCVæ•´ä½“çš„æµç¨‹ç›®å‰ä¹Ÿæœ‰äº†æ›´å¥½çš„æŠŠæ¡.

ä¸Šé¢ä¸€æ®µæ‰¯äº†é‚£ä¹ˆå¤š,æˆ‘ä»¬æ¥è¿è¡Œå‘½ä»¤`python tools/misc/print_config.py /home/lry/projects/mmdetection/configs/balloon/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py  `æ¥çœ‹çœ‹configåˆ°åº•æ˜¯ä»€ä¹ˆä¸œè¥¿:
æˆ‘å…ˆæŠŠå¾—åˆ°çš„æ•´ä¸ªçš„ç»“æœå¤åˆ¶ä¸‹æ¥ä»¥ä¾¿å„ä½ç ”ç©¶:
```python
Config:
model = dict(
    type='MaskRCNN',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=False),
        norm_eval=True,
        style='caffe',
        init_cfg=dict(
            type='Pretrained',
            checkpoint='open-mmlab://detectron2/resnet50_caffe')),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=1,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=dict(
            type='FCNMaskHead',
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=1,
            loss_mask=dict(
                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            mask_size=28,
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
dataset_type = 'COCODataset'
data_root = 'data/coco/'
img_norm_cfg = dict(
    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='LoadAnnotations',
        with_bbox=True,
        with_mask=True,
        poly2mask=False),
    dict(
        type='Resize',
        img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),
                   (1333, 768), (1333, 800)],
        multiscale_mode='value',
        keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[103.53, 116.28, 123.675],
        std=[1.0, 1.0, 1.0],
        to_rgb=False),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1333, 800),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type='CocoDataset',
        ann_file=
        '/home/lry/projects/mmdetection/data/balloon/train/annotation_coco.json',
        img_prefix='/home/lry/projects/mmdetection/data/balloon/train/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='LoadAnnotations',
                with_bbox=True,
                with_mask=True,
                poly2mask=False),
            dict(
                type='Resize',
                img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736),
                           (1333, 768), (1333, 800)],
                multiscale_mode='value',
                keep_ratio=True),
            dict(type='RandomFlip', flip_ratio=0.5),
            dict(
                type='Normalize',
                mean=[103.53, 116.28, 123.675],
                std=[1.0, 1.0, 1.0],
                to_rgb=False),
            dict(type='Pad', size_divisor=32),
            dict(type='DefaultFormatBundle'),
            dict(
                type='Collect',
                keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks'])
        ],
        classes=('balloon', )),
    val=dict(
        type='CocoDataset',
        ann_file=
        '/home/lry/projects/mmdetection/data/balloon/val/annotation_coco.json',
        img_prefix='/home/lry/projects/mmdetection/data/balloon/val/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[103.53, 116.28, 123.675],
                        std=[1.0, 1.0, 1.0],
                        to_rgb=False),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        classes=('balloon', )),
    test=dict(
        type='CocoDataset',
        ann_file=
        '/home/lry/projects/mmdetection/data/balloon/val/annotation_coco.json',
        img_prefix='/home/lry/projects/mmdetection/data/balloon/val/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1333, 800),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[103.53, 116.28, 123.675],
                        std=[1.0, 1.0, 1.0],
                        to_rgb=False),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ],
        classes=('balloon', )))
evaluation = dict(metric=['bbox', 'segm'])
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'
resume_from = None
workflow = [('train', 1)]
classes = ('balloon', )
```

æˆ‘ä»¬ä¸€ä¸ªä¸€ä¸ªæ…¢æ…¢çœ‹,å®é™…ä¸Šå°±æ˜¯æ£€æµ‹åˆ†å‰²çš„å„ä¸ªç»“æ„æµç¨‹(backbone, neck, rpn_head, roi_head)ä»¥åŠæˆ‘ä»¬è®­ç»ƒéªŒè¯æ•°æ®çš„æ ¼å¼é¢„è®­ç»ƒæ–¹æ³•(train_cfg, data_type, data_root, train_pipeline, test...)ä»¥åŠå„ç±»å…³äºæƒé‡ä½ç½®ã€å­¦ä¹ ç‡ã€ä¼˜åŒ–å‡½æ•°ç­‰ç­‰...:

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210515.png)

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210526.png)

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210532.png)

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210556.png)

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210539.png)

![](https://gitee.com/moisten-the-rain/image01/raw/master/img/20211109210544.png)

é™¤äº†ä»¥ä¸Šç»“æ„ä¹‹å¤–,å‰©ä¸‹çš„å°±æ˜¯ä¸€äº›æˆ‘ä»¬çš„å…¶ä½™é…ç½®:
```python
evaluation = dict(metric=['bbox', 'segm'])
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = 'https://download.openmmlab.com/mmdetection/v2.0/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'
resume_from = None
workflow = [('train', 1)]
classes = ('balloon', )
```



# 2021.11.10æ™šæ›´æ–°

## Preface 

æŒ‰ç…§æ˜¨å¤©çœ‹çš„è‡ªå·±ä¹‹å‰åšå®¢å’Œæ€»ç»“çš„æ€è·¯ï¼Œç›®å‰å½“åŠ¡ä¹‹æ€¥å°±æ˜¯æ‰¾åˆ°æˆ‘ä»¬éœ€è¦çš„ä»£ç æ¥è½¬æ¢labelmeæ ‡æ³¨çš„æ•°æ®é›†å˜ä¸ºCOCOæ ¼å¼çš„ï¼Œç›®å‰åœ¨GitHubæˆ‘æ‰¾åˆ°äº†ä¸€äº›ç›¸å…³çš„å¼€æºå°é¡¹ç›®ï¼Œæ‰“ç®—æ ¹æ®è¿™ä¸ªä»“åº“https://github.com/veraposeidon/labelme2Datasets æ¥è½¬æ¢æˆ‘ä»¬çš„æ•°æ®ï¼Œå½“ç„¶è¿™é‡Œè‚¯å®šéœ€è¦æ›´æ”¹ä¸€äº›ä»£ç ã€‚å¦å¤–è¿™é‡Œç”±äºåˆ†å‰²å¹¶æ²¡æœ‰åšæ•°æ®æ ‡æ³¨ï¼Œæ‰€ä»¥æˆ‘è‡ªå·±å¾—é‡æ–°å†™ä¸€éåˆ†å‰²çš„ç›¸å…³æ ‡æ³¨ã€‚



> çœŸæ˜¯æ‡’å¾—å¤Ÿå¯ä»¥ï¼Œ11.10æ•´å®Œçš„ï¼Œè¦ç­‰åˆ°11.13å·æ¥å†™ï¼Œåäº†ã€‚

## COCO.jsonå’ŒLabelme.jsonåŒºåˆ«
~~å¾…æ›´~~
2021.11.13å·²æ›´æ–°ã€‚

ä¸Šé¢æœ‰æåˆ°Labelme.jsonæ–‡ä»¶ä¸»è¦æ ¼å¼ï¼ŒCOCOæ•°æ®é›†å¤§æ¦‚é•¿è¿™ä¸ªæ ·å­ï¼š
```python
{
    "images": [image],
    "annotations": [annotation],
    "categories": [category]
}


image = {
    "id": int,
    "width": int,
    "height": int,
    "file_name": str,
}

annotation = {
    "id": int,
    "image_id": int,
    "category_id": int,
    "segmentation": RLE or [polygon],
    "area": float,
    "bbox": [x,y,width,height],
    "iscrowd": 0 or 1,
}

categories = [{
    "id": int,
    "name": str,
    "supercategory": str,
}]
```
COCOçš„jsonæ–‡ä»¶æ˜¯æ‰€æœ‰å›¾ç‰‡éƒ½æ”¾åˆ°ä¸€ä¸ªjsonæ–‡ä»¶ä¸­ï¼Œå¹¶ä¸”ç±»åˆ«ã€å›¾ç‰‡æå‰éƒ½ç”¨ç¼–å·idå®šä¹‰å¥½ã€‚



æˆ‘ä»¬å¯ä»¥ç»§ç»­çœ‹ä¸€ä¸‹Labelme.jsonæ–‡ä»¶åŒ…å«ä»€ä¹ˆï¼š

```python
{
  "version": "4.5.13",
  "flags": {},
  "shapes": [
    {
      "label": "780B",
      "points": [
        [
          734.0,
          2425.0
        ],
        [
          2779.0,
          2355.0
        ],
        [
          2584.0,
          3580.0
        ],
        [
          819.0,
          3770.0
        ]
      ],
      "group_id": null,
      "shape_type": "polygon",
      "flags": {}
    },
    ...
    {
    "label":"780B",
    "points":[
    	...
    ],
    "group_id": null,
      "shape_type": "polygon",
      "flags": {}
    }
  ],
  "imagePath": "IMG_20211021_154043.jpg",
  "imageData": null,
  "imageHeight": 4608,
  "imageWidth": 3456
}
```
labelmeæ–‡ä»¶æ˜¯æ¯ä¸€ä¸ªå›¾ç‰‡éƒ½æœ‰è‡ªå·±çš„jsonæ–‡ä»¶è´Ÿè´£å­˜å‚¨å„ä¸ªå›¾ç‰‡ã€‚

å¦å¤–è¿™é‡Œä»‹ç»ä¸€ä¸‹COCOæ•°æ®é›†ä¸­çš„segmentationç±»å‹çš„labelæ˜¯ä»€ä¹ˆæ ·å­çš„ï¼Œå®é™…ä¸Šå°±æ˜¯ç±»ä¼¼äºå¤šè¾¹å½¢çš„æ¯ä¸€ä¸ªé¡¶ç‚¹è¿™ä¸ªæ ·å¼ï¼Œè¿™å¯¹æˆ‘ä»¬ç›®å‰çš„æ•°æ®é›†éå¸¸æ–¹ä¾¿ï¼Œå› ä¸ºæˆ‘ä»¬ç›®å‰æ•°æ®é›†å¹¶æ²¡æœ‰æ ‡æ³¨æ¯ä¸€ä¸ªç‰©ä½“çš„åˆ†å‰²æ•°æ®é›†ï¼Œä½†æ˜¯æˆ‘ä»¬çš„ç›®æ ‡æœ¬èº«å°±æ˜¯çŸ©å½¢æ¡†ï¼Œæ‰€ä»¥æˆ‘ä»¬ç›´æ¥ç”¨æ£€æµ‹çš„labelå°±å¯ä»¥ç›´æ¥è½¬åŒ–ä¸ºCOCOæ ¼å¼çš„åˆ†å‰²çš„labelã€‚å› ä¸ºéƒ½æ˜¯åªæœ‰4ä¸ªç‚¹å°±å¯ä»¥ã€‚





## è½¬æ¢æºç åˆå§‹ç‰ˆ 


ç›®å‰æ‰“ç®—è½¬æ¢çš„æºç å¦‚ä¸‹ï¼š
```python
"""æœ¬æ¨¡å—ç”¨äºæ‰¹é‡è½¬æ¢labelmeæ ‡è®°çš„æ ¼å¼ï¼Œä½¿ä¹‹å˜æˆcocoæ•°æ®é›†æ ¼å¼"""
# -*- coding:utf-8 -*-
# !/usr/bin/env python


import argparse
import json
import matplotlib.pyplot as plt
import skimage.io as io
import cv2
from labelme import utils
import numpy as np
import glob
import PIL.Image


class MyEncoder(json.JSONEncoder):
	def default(self, obj):
		if isinstance(obj, np.integer):
			return int(obj)
		elif isinstance(obj, np.floating):
			return float(obj)
		elif isinstance(obj, np.ndarray):
			return obj.tolist()
		else:
			return super(MyEncoder, self).default(obj)


class labelme2coco(object):
	def __init__(self, labelme_json=[], save_json_path='./tran.json'):
		'''
		labelme_json: æ‰€æœ‰labelmeçš„jsonæ–‡ä»¶è·¯å¾„ç»„æˆçš„åˆ—è¡¨
		save_json_path: jsonä¿å­˜ä½ç½®
		'''
		self.labelme_json = labelme_json
		self.save_json_path = save_json_path
		self.images = []
		self.categories = []
		self.annotations = []
		# self.data_coco = {}
		self.label = []
		self.annID = 1
		self.height = 0
		self.width = 0

		self.save_json()

	def data_transfer(self):

		for num, json_file in enumerate(self.labelme_json):
			print("num:" + str(num + 1) + '    ' + json_file)
			with open(json_file, 'r') as fp:
				data = json.load(fp)  # åŠ è½½jsonæ–‡ä»¶
				self.images.append(self.image(data, num))
				for shapes in data['shapes']:
					label = shapes['label']
					if label not in self.label:
						self.categories.append(self.categorie(label))
						self.label.append(label)
					points = shapes['points']  # è¿™é‡Œçš„pointæ˜¯ç”¨rectangleæ ‡æ³¨å¾—åˆ°çš„ï¼Œåªæœ‰ä¸¤ä¸ªç‚¹ï¼Œéœ€è¦è½¬æˆå››ä¸ªç‚¹
					#points.append([points[0][0], points[1][1]])
					#points.append([points[1][0], points[0][1]])
					self.annotations.append(self.annotation(points, label, num))
					self.annID += 1

	def image(self, data, num):
		image = {}
		img = utils.img_b64_to_arr(data['imageData'])  # è§£æåŸå›¾ç‰‡æ•°æ®
		# img=io.imread(data['imagePath']) # é€šè¿‡å›¾ç‰‡è·¯å¾„æ‰“å¼€å›¾ç‰‡
		# img = cv2.imread(data['imagePath'], 0)
		height, width = img.shape[:2]
		img = None
		image['height'] = height
		image['width'] = width
		image['id'] = num + 1
		#image['file_name'] = data['imagePath'].split("\\")[-1] #æ­¤è¡Œä¸é€‚åˆæˆ‘çš„æ•°æ®é›†
		image['file_name'] = data['imagePath'].split("\\")[-1].split('..')[-1]

		self.height = height
		self.width = width

		return image

	def categorie(self, label):
		categorie = {}
		categorie['supercategory'] = 'Cancer'
		categorie['id'] = len(self.label) + 1  # 0 é»˜è®¤ä¸ºèƒŒæ™¯
		categorie['name'] = label
		return categorie

	def annotation(self, points, label, num):
		annotation = {}
		annotation['segmentation'] = [list(np.asarray(points).flatten())]
		annotation['iscrowd'] = 0
		annotation['image_id'] = num + 1
		# annotation['bbox'] = str(self.getbbox(points)) # ä½¿ç”¨listä¿å­˜jsonæ–‡ä»¶æ—¶æŠ¥é”™ï¼ˆä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼‰
		# list(map(int,a[1:-1].split(','))) a=annotation['bbox'] ä½¿ç”¨è¯¥æ–¹å¼è½¬æˆlist
		annotation['bbox'] = list(map(float, self.getbbox(points)))
		annotation['area'] = annotation['bbox'][2] * annotation['bbox'][3]
		# annotation['category_id'] = self.getcatid(label)
		annotation['category_id'] = self.getcatid(label)  # æ³¨æ„ï¼Œæºä»£ç é»˜è®¤ä¸º1
		annotation['id'] = self.annID
		return annotation

	def getcatid(self, label):
		for categorie in self.categories:
			if label == categorie['name']:
				return categorie['id']
		return 1

	def getbbox(self, points):
		# img = np.zeros([self.height,self.width],np.uint8)
		# cv2.polylines(img, [np.asarray(points)], True, 1, lineType=cv2.LINE_AA)  # ç”»è¾¹ç•Œçº¿
		# cv2.fillPoly(img, [np.asarray(points)], 1)  # ç”»å¤šè¾¹å½¢ å†…éƒ¨åƒç´ å€¼ä¸º1
		polygons = points

		mask = self.polygons_to_mask([self.height, self.width], polygons)
		#print(polygons)
		return self.mask2box(mask)

	def mask2box(self, mask):
		'''ä»maskåç®—å‡ºå…¶è¾¹æ¡†
		maskï¼š[h,w]  0ã€1ç»„æˆçš„å›¾ç‰‡
		1å¯¹åº”å¯¹è±¡ï¼Œåªéœ€è®¡ç®—1å¯¹åº”çš„è¡Œåˆ—å·ï¼ˆå·¦ä¸Šè§’è¡Œåˆ—å·ï¼Œå³ä¸‹è§’è¡Œåˆ—å·ï¼Œå°±å¯ä»¥ç®—å‡ºå…¶è¾¹æ¡†ï¼‰
		'''
		# np.where(mask==1)
		index = np.argwhere(mask == 1)
		#print(index)


		rows = index[:, 0]
		clos = index[:, 1]
		# è§£æå·¦ä¸Šè§’è¡Œåˆ—å·
		#print(rows)
		left_top_r = np.min(rows)  # y
		left_top_c = np.min(clos)  # x

		# è§£æå³ä¸‹è§’è¡Œåˆ—å·
		right_bottom_r = np.max(rows)
		right_bottom_c = np.max(clos)

		# return [(left_top_r,left_top_c),(right_bottom_r,right_bottom_c)]
		# return [(left_top_c, left_top_r), (right_bottom_c, right_bottom_r)]
		# return [left_top_c, left_top_r, right_bottom_c, right_bottom_r]  # [x1,y1,x2,y2]
		return [left_top_c, left_top_r, right_bottom_c - left_top_c,
		        right_bottom_r - left_top_r]  # [x1,y1,w,h] å¯¹åº”COCOçš„bboxæ ¼å¼

	def polygons_to_mask(self, img_shape, polygons):
		mask = np.zeros(img_shape, dtype=np.uint8)
		mask = PIL.Image.fromarray(mask)
		xy = list(map(tuple, polygons))
		PIL.ImageDraw.Draw(mask).polygon(xy=xy, outline=1, fill=1)
		mask = np.array(mask, dtype=bool)
		return mask

	def data2coco(self):
		data_coco = {}
		data_coco['images'] = self.images
		data_coco['categories'] = self.categories
		data_coco['annotations'] = self.annotations
		return data_coco

	def save_json(self):
		self.data_transfer()
		self.data_coco = self.data2coco()
		# ä¿å­˜jsonæ–‡ä»¶
		json.dump(self.data_coco, open(self.save_json_path, 'w'), indent=4, cls=MyEncoder)  # indent=4 æ›´åŠ ç¾è§‚æ˜¾ç¤º


labelme_json = glob.glob('H:/camellia/Aug/è®­ç»ƒ/val_json/*.json')
print(labelme_json)

# labelme_json=['./Annotations/*.json']
# labelme_json=glob.glob('./Annotations/*.json')

saveme_json = 'H:/camellia/Aug/è®­ç»ƒ/annotations/val.json'
print("Start.")

labelme2coco(labelme_json, saveme_json)
print("Finished.")
```


## ä»£ç è¯¦è§£
æŒ‰ç…§è¿è¡Œé¡ºåºæ¥è§£é‡Šä»£ç ï¼š

### main()
å…³äºä»¥ä¸Šä»£ç ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®è¿è¡Œçš„é¡ºåºæ¥å®šä¹‰ï¼Œé¦–å…ˆæ˜¯globäº†æ‰€æœ‰.jsonå‰ç¼€çš„æ–‡ä»¶ï¼Œå› ä¸ºæˆ‘ä»¬labelmeçš„æ–‡ä»¶éƒ½æ˜¯ä¸€ä¸ªå›¾ç‰‡ä¸“é—¨ç”Ÿæˆä¸€ä¸ª.jsonæ–‡ä»¶ï¼Œè€Œæˆ‘ä»¬çš„COCOæ•°æ®é›†æ ¼å¼æ˜¯æ‰€æœ‰çš„å›¾ç‰‡çš„ä¿¡æ¯éƒ½æ”¾åˆ°äº†ä¸€ä¸ª.jsonå›¾ç‰‡ä¸­ï¼Œæ¥ç€æˆ‘ä»¬å®šä¹‰ä¿å­˜åˆ°çš„jsonæ–‡ä»¶ï¼Œç„¶åç›´æ¥è°ƒç”¨ç±»labelme2coco,ç„¶åç›´æ¥å¾—åˆ°çš„ç»“æœã€‚


### labelme2coco
labelme2cocoæ˜¯æ•´ä¸ªæ–‡ä»¶çš„å…³é”®ã€‚

### `__init__`
```python
class labelme2coco(object):
	def __init__(self, labelme_json=[], save_json_path='./tran.json'):  # è¿™é‡Œå®šä¹‰äº†é»˜è®¤çš„å­˜å‚¨è·¯å¾„
		'''
		labelme_json: æ‰€æœ‰labelmeçš„jsonæ–‡ä»¶è·¯å¾„ç»„æˆçš„åˆ—è¡¨
		save_json_path: jsonä¿å­˜ä½ç½®
		'''
		self.labelme_json = labelme_json     # labelme_jsonçš„æ–‡ä»¶è·¯å¾„ï¼Œæ˜¯ä¸€ä¸ªåˆ—è¡¨å­˜å‚¨ç€æ‰€æœ‰çš„å¾…è½¬åŒ–jsonæ–‡ä»¶è·¯å¾„
		self.save_json_path = save_json_path  # ä¿å­˜çš„è·¯å¾„
		self.images = []  # å¯¹åº”ç”ŸæˆCOCOå½¢å¼jsonæ–‡ä»¶çš„imageçš„ç±»å‹ã€‚
		self.categories = [] # åŒä¸Š
		self.annotations = [] # åŒä¸Š
		# self.data_coco = {}
		self.label = []
		self.annID = 1
		self.height = 0
		self.width = 0

		self.save_json()  # æ³¨æ„è¿™é‡Œä¸€è°ƒç”¨è¯¥ç±»å°±ç›´æ¥è¿è¡Œç›¸å…³çš„æ‰€æœ‰ä»£ç äº†ï¼Œè¿™ä¸ªæŠ€å·§å¾ˆæœ‰ç”¨ã€‚
```
æˆ‘ä»¬æ¥ä¸‹æ¥åº”è¯¥çœ‹`save_json()`ï¼š


### save_json()

```python
	def save_json(self):
		self.data_transfer()
		self.data_coco = self.data2coco()
		# ä¿å­˜jsonæ–‡ä»¶
		json.dump(self.data_coco, open(self.save_json_path, 'w'), indent=4, cls=MyEncoder)  # indent=4 æ›´åŠ ç¾è§‚æ˜¾ç¤º
```
è¿™ä¸ªå¯ä»¥çœ‹åˆ°å®é™…ä¸Šå°±æ˜¯ä¸€ä¸ªè°ƒç”¨çš„ç±»å†…çš„å‡½æ•°æ¥æ€»ä½“è°ƒç”¨ã€‚æˆ‘ä»¬ç»§ç»­æ¥çœ‹data_transfer()

### data_transfer()
```python
	def data_transfer(self):

		for num, json_file in enumerate(self.labelme_json):
			print("num:" + str(num + 1) + '    ' + json_file)
			with open(json_file, 'r') as fp:
				data = json.load(fp)  # åŠ è½½jsonæ–‡ä»¶
				self.images.append(self.image(data, num))  # æ³¨æ„è¿™ä¸ªimageæ˜¯ä¸ªå‡½æ•°ï¼ å°†è¯¥å›¾ç‰‡çš„æ‰€æœ‰ç›¸åº”çš„ä¿¡æ¯è½¬åŒ–ä¸ºCOCOçš„imageæ ¼å¼
				for shapes in data['shapes']:   # shapesæ˜¯ä¸»è¦çš„æ ‡æ³¨ä¿¡æ¯ï¼Œæˆ‘ä»¬é‡ç‚¹å°±æ˜¯è¯»å–è¿™ä¸ªï¼Œä½†æ˜¯æˆ‘ä»¬æ²¡æœ‰å¿…è¦è¯»å–æ‰€æœ‰ï¼Œå¯èƒ½åªéœ€è¦è¯»å–ç¬¬ä¸€ä¸ª780bå°±å¯ä»¥
					label = shapes['label']  # æ³¨æ„è¿™é‡Œæ˜¯ä¸€ä¸ªå¾ªç¯ï¼Œè¿™ä¸ªå¾ªç¯å°†æ‰€æœ‰çš„labelæœ‰å…³æ–‡ä»¶éƒ½å¾ªç¯äº†ä¸€é
					if label not in self.label:
						self.categories.append(self.categorie(label))  # æ³¨æ„è¿™ä¸ªself.categorieä¹Ÿæ˜¯ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªä»£ç æ®µå°±æ˜¯è¦ç”ŸæˆCOCOçš„categoriesæ ¼å¼
						self.label.append(label)
					points = shapes['points']  # è¿™é‡Œçš„pointæ˜¯ç”¨rectangleæ ‡æ³¨å¾—åˆ°çš„ï¼Œåªæœ‰ä¸¤ä¸ªç‚¹ï¼Œéœ€è¦è½¬æˆå››ä¸ªç‚¹
					#points.append([points[0][0], points[1][1]])
					#points.append([points[1][0], points[0][1]])
					self.annotations.append(self.annotation(points, label, num)) # åŒæ ·çš„ï¼Œself.annotationä¹Ÿæ˜¯ä¸€ä¸ªç›¸åº”çš„å‡½æ•°è¦å°†æ‰€ç»™çš„pointsæ–‡ä»¶è½¬åŒ–ä¸ºannotationå’Œsegmentationæ–‡ä»¶
					self.annID += 1
```

è¿™é‡Œä¸€æ­¥ä¸€æ­¥è¯´ï¼Œé¦–å…ˆå°±æ˜¯è¦å°†æ‰€æœ‰çš„jsonæ–‡ä»¶å¾ªç¯éå†ä¸€éï¼Œä¹‹åæ‰“å¼€æ¯ä¸ªæ–‡ä»¶ï¼Œé¦–å…ˆåŠ è½½æ–‡ä»¶ï¼Œä¹‹åè°ƒç”¨ç±»ä¸­å®šä¹‰å¥½çš„self.image()å‡½æ•°,è¿™ä¸ªå‡½æ•°å°†è¯¥å›¾ç‰‡æ‰€æœ‰ç›¸åº”çš„ä¿¡æ¯è½¬åŒ–æˆCOCOçš„imageçš„æ ¼å¼ç„¶åè¿”å›COCOæ ¼å¼çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬å°†è¿™ä¸ªä¿¡æ¯åŠ åˆ°self.imagesä¸­å»ã€‚æˆ‘ä»¬å…ˆè§£æä¸€ä¸‹ç›¸å…³çš„self.image()å‡½æ•°ã€‚

### image()
å®é™…ä¸Šimage()éœ€è¦çš„ä¿¡æ¯ä¹Ÿå°±æ˜¯ä¸€ä¸ªå›¾ç‰‡çš„é«˜å®½ã€å°†å›¾ç‰‡æ•´ç†æˆç¼–å·ï¼Œå›¾ç‰‡åã€‚
```python
image = {
    "id": int,
    "width": int,
    "height": int,
    "file_name": str,
}
```
imageå‡½æ•°å®é™…ä¸Šå°±æ˜¯è¯»å–äº†ä»¥ä¸Šçš„æä¾›çš„ä¿¡æ¯ç„¶åè½¬åŒ–è¿‡å»ï¼š
```python
	def image(self, data, num):
		image = {}
		img = utils.img_b64_to_arr(data['imageData'])  # è§£æåŸå›¾ç‰‡æ•°æ®ï¼Œæ³¨æ„æˆ‘ä»¬å¹¶ä¸æ˜¯æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰,æ€ªä¸å¾—æ‰€æœ‰æ–‡ä»¶éƒ½æ‰“å¼€è¿è¡Œä¼šæŠ¥é”™ï¼ŒçœŸæ˜¯å¥½å¥‡æ€ªï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡æ–‡ä»¶è·¯å¾„æ‰“å¼€ï¼Œå‚è§ä¸‹ä¸€è¡Œä»£ç 
		# img=io.imread(os.path.join(root, data['imagePath'])) # é€šè¿‡å›¾ç‰‡è·¯å¾„æ‰“å¼€å›¾ç‰‡ï¼Œ ä¸è¿‡è¿™ä¸ªå°±éœ€è¦è®¾ä¸€ä¸ªå…¨å±€çš„root
		# img = cv2.imread(data['imagePath'], 0)
		height, width = img.shape[:2]
		img = None
		image['height'] = height
		image['width'] = width
		image['id'] = num + 1
		#image['file_name'] = data['imagePath'].split("\\")[-1] #æ­¤è¡Œä¸é€‚åˆæˆ‘çš„æ•°æ®é›†
		image['file_name'] = data['imagePath'].split("\\")[-1].split('..')[-1]

		self.height = height
		self.width = width

		return image
```
æ³¨æ„åˆ°æˆ‘ä»¬æœ€ç»ˆè¿”å›çš„æ˜¯ä¸€ä¸ªå­—å…¸ã€‚
è¿™é‡Œæˆ‘ä»¬å‘ç°ç”¨åˆ°äº†ä¸€ä¸ªå‡½æ•°utils.img_b64_to_arr()ï¼Œè¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥å°†æˆ‘ä»¬çš„å›¾ç‰‡è¯»å–æˆcv2çš„imgæ ¼å¼çŸ©é˜µï¼Œè¿™ä¸ªutilså®é™…ä¸Šæ˜¯labelmeè¿™ä¸ªåº“ä¸­çš„ä¸€ä¸ªæ¨¡å—ã€‚ç›®å‰æˆ‘çš„ç†è§£æ˜¯ï¼Œlabelmeç”Ÿæˆçš„.jsonæ–‡ä»¶é‡Œé¢çš„imageDataæ˜¯ä¸€å †æˆ‘çœ‹ä¸æ‡‚çš„ç¼–ç ï¼Œè¿™äº›ç¼–ç å®é™…ä¸Šå­˜å‚¨çš„å°±æ˜¯å›¾ç‰‡çš„ä¿¡æ¯ï¼Œç„¶åæˆ‘ä»¬é€šè¿‡`img_b64_to_arr()`å‡½æ•°æ¥â€œç¿»è¯‘â€ä¸ºæˆ‘ä»¬èƒ½çœ‹æ‡‚çš„å›¾ç‰‡RGBçŸ©é˜µå½¢å¼å­˜å‚¨ã€‚
å¯ä»¥çœ‹åˆ°ä¸‹é¢çš„æ³¨é‡Šä¹Ÿç»™å‡ºäº†ä¸€äº›å…¶ä»–æ–¹å¼çš„æ‰“å¼€å›¾ç‰‡å½¢å¼ï¼Œæœ‰ç”¨cv2è¯»å–ï¼Œæœ‰ç”¨skimage.ioè¯»å–çš„ï¼Œå› ä¸ºæœ‰å¯èƒ½æˆ‘ä»¬data['imageData']çš„å€¼ä¸ºnull(~~æˆ‘ç›®å‰é¡¹ç›®çš„æ•°æ®é›†å°±æ˜¯è¿™æ ·~~)ã€‚å…¶ä»–çš„æ ¼å¼éƒ½æ˜¯å¾ˆç®€å•çš„å¤åˆ¶äº†ï¼Œç›¸å¯¹è€Œè¨€ä¸ç”¨å¤šè¯´ã€‚

### data_transfer()

å¥½äº†æˆ‘ä»¬æ¥ä¸‹æ¥ç»§ç»­è¯´æˆ‘ä»¬çš„data_transfer()å‡½æ•°ã€‚æ¥ä¸‹æ¥æ˜¯å¯¹data['shapes']æ‰€æœ‰æ–‡ä»¶è¿›è¡Œä¸€ä¸ªéå†ï¼Œshapesæ˜¯ä¸»è¦çš„æ ‡æ³¨ä¿¡æ¯ï¼Œæˆ‘ä»¬é‡ç‚¹å°±æ˜¯è¯»å–è¿™ä¸ªï¼Œshapesé‡Œé¢åŒ…å«ç€æ‰€æœ‰çš„æ ‡æ³¨æ¡†ground truthä¿¡æ¯ï¼Œå½“ç„¶æˆ‘ä»¬è¿™é‡Œå› ä¸ºä»…ä»…å¯¹ä¸€ä¸ªå¤§æ¡†åšåˆ†å‰²æ‰€ä»¥åªéœ€è¦ä¸€ä¸ª780Bçš„labelå°±å¯ä»¥ï¼Œè¿™é‡Œå®ƒå°†æ‰€æœ‰éƒ½éå†äº†ä¸€éï¼Œç„¶åè°ƒç”¨äº†self.categorieå‡½æ•°æ¥è®©æˆ‘ä»¬çš„labelé‡Œé¢çš„ä¿¡æ¯è½¬åŒ–ä¸ºCOCOæ ¼å¼çš„ã€‚å®é™…ä¸Šå°±æ˜¯å˜ä¸ºCOCOæ ¼å¼jsonæ–‡ä»¶ä¸­é‚£ä¸ªcategoriesç±»å‹ï¼Œæˆ‘ä»¬ç»§ç»­æ¥çœ‹self.categorie()

### categorie()
```python
	def categorie(self, label):
		categorie = {}
		categorie['supercategory'] = 'Cancer'
		categorie['id'] = len(self.label) + 1  # 0 é»˜è®¤ä¸ºèƒŒæ™¯
		categorie['name'] = label
		return categorie
```
å®é™…ä¸Šéå¸¸ç®€å•ï¼Œå› ä¸ºCOCOé‡Œé¢çš„categoriesåªéœ€è¦çŸ¥é“æ•´ä¸ªæ•°æ®é›†æœ‰å“ªäº›ç±»ï¼Œæ¯ä¸ªç±»éƒ½æœ‰ä¸€ä¸ªå¯¹åº”çš„idå°±OKäº†ã€‚

### data_transfer()
å®é™…ä¸Šåé¢éƒ½æ˜¯ç±»ä¼¼çš„ï¼Œå¯¹åº”çš„åŠŸèƒ½è°ƒç”¨ç›¸åº”çš„å‡½æ•°å°±OKã€‚è¿™é‡Œä¸è¯¦ç»†è°ˆäº†ï¼Œæ²¡æœ‰å¿…è¦è¯¦ç»†è§£é‡Šã€‚

### data2coco()
éšåæˆ‘ä»¬çœ‹åˆ°è¿™é‡Œè°ƒç”¨äº†ç›¸å…³çš„å‡½æ•°è½¬åŒ–ä¸ºjsonæ–‡ä»¶éœ€è¦çš„å­—å…¸æ ¼å¼ï¼š
```python
	def data2coco(self):
		data_coco = {}
		data_coco['images'] = self.images
		data_coco['categories'] = self.categories
		data_coco['annotations'] = self.annotations
		return data_coco
```

æœ€åè¿›è¡Œä¸€ä¸‹json.dumpå°±æˆåŠŸä¿å­˜å¥½jsonæ–‡ä»¶äº†ã€‚


## è½¬åŒ–ä»£ç æœ€ç»ˆæ”¹è‰¯ç‰ˆ
ç»è¿‡ä¸Šè¿°æè¿°ï¼Œæœ€ç»ˆåšä¸€ä¸ªæ”¹è‰¯ï¼Œå¾—åˆ°ç›¸åº”çš„ç»“æœï¼š

```python
"""æœ¬æ¨¡å—ç”¨äºæ‰¹é‡è½¬æ¢labelmeæ ‡è®°çš„æ ¼å¼ï¼Œä½¿ä¹‹å˜æˆcocoæ•°æ®é›†æ ¼å¼"""
# -*- coding:utf-8 -*-
# !/usr/bin/env python


import argparse
import json
import matplotlib.pyplot as plt
import skimage.io as io
import cv2
from labelme import utils
import numpy as np
import glob
import PIL.Image
import os


class MyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return super(MyEncoder, self).default(obj)


class labelme2coco(object):

    def __init__(self, labelme_json=[], save_json_path='./tran.json'):  # è¿™é‡Œå®šä¹‰äº†é»˜è®¤çš„å­˜å‚¨è·¯å¾„
        '''
        labelme_json: æ‰€æœ‰labelmeçš„jsonæ–‡ä»¶è·¯å¾„ç»„æˆçš„åˆ—è¡¨
        save_json_path: jsonä¿å­˜ä½ç½®
        '''
        self.labelme_json = labelme_json     # labelme_jsonçš„æ–‡ä»¶è·¯å¾„ï¼Œæ˜¯ä¸€ä¸ªåˆ—è¡¨å­˜å‚¨ç€æ‰€æœ‰çš„å¾…è½¬åŒ–jsonæ–‡ä»¶è·¯å¾„
        self.save_json_path = save_json_path  # ä¿å­˜çš„è·¯å¾„
        self.images = []  # å¯¹åº”ç”ŸæˆCOCOå½¢å¼jsonæ–‡ä»¶çš„imageçš„ç±»å‹ã€‚
        self.categories = []  # åŒä¸Š
        self.annotations = []  # åŒä¸Š
        # self.data_coco = {}
        self.label = []
        self.annID = 1
        self.height = 0
        self.width = 0
        self.root = '/home/lry/projects/mmdetection/data/780b/'

        self.save_json()  # æ³¨æ„è¿™é‡Œä¸€è°ƒç”¨è¯¥ç±»å°±ç›´æ¥è¿è¡Œç›¸å…³çš„æ‰€æœ‰ä»£ç äº†ï¼Œè¿™ä¸ªæŠ€å·§å¾ˆæœ‰ç”¨ã€‚

    def data_transfer(self):

        for num, json_file in enumerate(self.labelme_json):
            print("num:" + str(num + 1) + '    ' + json_file)
            with open(json_file, 'r') as fp:
                data = json.load(fp)  # åŠ è½½jsonæ–‡ä»¶
                # æ³¨æ„è¿™ä¸ªimageæ˜¯ä¸ªå‡½æ•°ï¼ å°†è¯¥å›¾ç‰‡çš„æ‰€æœ‰ç›¸åº”çš„ä¿¡æ¯è½¬åŒ–ä¸ºCOCOçš„imageæ ¼å¼
                self.images.append(self.image(data, num))

                # shapesæ˜¯ä¸»è¦çš„æ ‡æ³¨ä¿¡æ¯ï¼Œæˆ‘ä»¬é‡ç‚¹å°±æ˜¯è¯»å–è¿™ä¸ªï¼Œä½†æ˜¯æˆ‘ä»¬æ²¡æœ‰å¿…è¦è¯»å–æ‰€æœ‰ï¼Œå¯èƒ½åªéœ€è¦è¯»å–ç¬¬ä¸€ä¸ª780bå°±å¯ä»¥
                for shapes in data['shapes']:

                    # é¦–å…ˆæˆ‘ä»¬ä¼šåˆ¤æ–­æ˜¯å¦è¿™ä¸ªlabelæ˜¯å¦æ˜¯"780B"
                    if shapes['label'] != "780B":
                        continue

                    # æ³¨æ„è¿™é‡Œæ˜¯ä¸€ä¸ªå¾ªç¯ï¼Œè¿™ä¸ªå¾ªç¯å°†æ‰€æœ‰çš„labelæœ‰å…³æ–‡ä»¶éƒ½å¾ªç¯äº†ä¸€é
                    label = shapes['label']
                    if label not in self.label:
                        # æ³¨æ„è¿™ä¸ªself.categorieä¹Ÿæ˜¯ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªä»£ç æ®µå°±æ˜¯è¦ç”ŸæˆCOCOçš„categoriesæ ¼å¼
                        self.categories.append(self.categorie(label))
                        self.label.append(label)
                    # è¿™é‡Œçš„pointæ˜¯ç”¨rectangleæ ‡æ³¨å¾—åˆ°çš„ï¼Œåªæœ‰ä¸¤ä¸ªç‚¹ï¼Œéœ€è¦è½¬æˆå››ä¸ªç‚¹
                    points = shapes['points']
                    #points.append([points[0][0], points[1][1]])
                    #points.append([points[1][0], points[0][1]])
                    # åŒæ ·çš„ï¼Œself.annotationä¹Ÿæ˜¯ä¸€ä¸ªç›¸åº”çš„å‡½æ•°è¦å°†æ‰€ç»™çš„pointsæ–‡ä»¶è½¬åŒ–ä¸ºannotationå’Œsegmentationæ–‡ä»¶
                    self.annotations.append(
                        self.annotation(points, label, num))
                    self.annID += 1


    def image(self, data, num):
        image = {}
        # è§£æåŸå›¾ç‰‡æ•°æ®ï¼Œæ³¨æ„æˆ‘ä»¬å¹¶ä¸æ˜¯æ‰€æœ‰æ–‡ä»¶éƒ½æœ‰,æ€ªä¸å¾—æ‰€æœ‰æ–‡ä»¶éƒ½æ‰“å¼€è¿è¡Œä¼šæŠ¥é”™ï¼ŒçœŸæ˜¯å¥½å¥‡æ€ªï¼Œä½†æ˜¯æˆ‘ä»¬å¯ä»¥é€šè¿‡æ–‡ä»¶è·¯å¾„æ‰“å¼€ï¼Œå‚è§ä¸‹ä¸€è¡Œä»£ç 
        try:
            img = utils.img_b64_to_arr(data['imageData'])
        except:
            img=io.imread(os.path.join(self.root, data['imagePath'])) # é€šè¿‡å›¾ç‰‡è·¯å¾„æ‰“å¼€å›¾ç‰‡ï¼Œ ä¸è¿‡è¿™ä¸ªå°±éœ€è¦è®¾ä¸€ä¸ªå…¨å±€çš„root
        # img = cv2.imread(data['imagePath'], 0)
        height, width = img.shape[:2]
        img = None
        image['height'] = height
        image['width'] = width
        image['id'] = num + 1
        # image['file_name'] = data['imagePath'].split("\\")[-1] #æ­¤è¡Œä¸é€‚åˆæˆ‘çš„æ•°æ®é›†
        image['file_name'] = data['imagePath'].split("\\")[-1].split('..')[-1]

        self.height = height
        self.width = width

        return image

    def categorie(self, label):
        categorie = {}
        # categorie['supercategory'] = 'Cancer'  # è¿™ä¸ªæ— ç”¨
        categorie['id'] = len(self.label) + 1  # 0 é»˜è®¤ä¸ºèƒŒæ™¯
        categorie['name'] = label
        return categorie

    def annotation(self, points, label, num):
        annotation = {}
        annotation['segmentation'] = [list(np.asarray(points).flatten())]
        annotation['iscrowd'] = 0
        annotation['image_id'] = num + 1
        # annotation['bbox'] = str(self.getbbox(points)) # ä½¿ç”¨listä¿å­˜jsonæ–‡ä»¶æ—¶æŠ¥é”™ï¼ˆä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼‰
        # list(map(int,a[1:-1].split(','))) a=annotation['bbox'] ä½¿ç”¨è¯¥æ–¹å¼è½¬æˆlist
        annotation['bbox'] = list(map(float, self.getbbox(points)))
        annotation['area'] = annotation['bbox'][2] * annotation['bbox'][3]
        # annotation['category_id'] = self.getcatid(label)
        annotation['category_id'] = self.getcatid(label)  # æ³¨æ„ï¼Œæºä»£ç é»˜è®¤ä¸º1
        annotation['id'] = self.annID
        return annotation

    def getcatid(self, label):
        for categorie in self.categories:
            if label == categorie['name']:
                return categorie['id']
        return 1

    def getbbox(self, points):
        # img = np.zeros([self.height,self.width],np.uint8)
        # cv2.polylines(img, [np.asarray(points)], True, 1, lineType=cv2.LINE_AA)  # ç”»è¾¹ç•Œçº¿
        # cv2.fillPoly(img, [np.asarray(points)], 1)  # ç”»å¤šè¾¹å½¢ å†…éƒ¨åƒç´ å€¼ä¸º1
        polygons = points

        mask = self.polygons_to_mask([self.height, self.width], polygons)
        # print(polygons)
        return self.mask2box(mask)

    def mask2box(self, mask):
        '''ä»maskåç®—å‡ºå…¶è¾¹æ¡†
        maskï¼š[h,w]  0ã€1ç»„æˆçš„å›¾ç‰‡
        1å¯¹åº”å¯¹è±¡ï¼Œåªéœ€è®¡ç®—1å¯¹åº”çš„è¡Œåˆ—å·ï¼ˆå·¦ä¸Šè§’è¡Œåˆ—å·ï¼Œå³ä¸‹è§’è¡Œåˆ—å·ï¼Œå°±å¯ä»¥ç®—å‡ºå…¶è¾¹æ¡†ï¼‰
        '''
        # np.where(mask==1)
        index = np.argwhere(mask == 1)
        # print(index)

        rows = index[:, 0]
        clos = index[:, 1]
        # è§£æå·¦ä¸Šè§’è¡Œåˆ—å·
        # print(rows)
        left_top_r = np.min(rows)  # y
        left_top_c = np.min(clos)  # x

        # è§£æå³ä¸‹è§’è¡Œåˆ—å·
        right_bottom_r = np.max(rows)
        right_bottom_c = np.max(clos)

        # return [(left_top_r,left_top_c),(right_bottom_r,right_bottom_c)]
        # return [(left_top_c, left_top_r), (right_bottom_c, right_bottom_r)]
        # return [left_top_c, left_top_r, right_bottom_c, right_bottom_r]  # [x1,y1,x2,y2]
        return [left_top_c, left_top_r, right_bottom_c - left_top_c,
                right_bottom_r - left_top_r]  # [x1,y1,w,h] å¯¹åº”COCOçš„bboxæ ¼å¼

    def polygons_to_mask(self, img_shape, polygons):
        mask = np.zeros(img_shape, dtype=np.uint8)
        mask = PIL.Image.fromarray(mask)
        xy = list(map(tuple, polygons))
        PIL.ImageDraw.Draw(mask).polygon(xy=xy, outline=1, fill=1)
        mask = np.array(mask, dtype=bool)
        return mask

    def data2coco(self):
        data_coco = {}
        data_coco['images'] = self.images
        data_coco['categories'] = self.categories
        data_coco['annotations'] = self.annotations
        return data_coco

    def save_json(self):
        self.data_transfer()
        self.data_coco = self.data2coco()
        # ä¿å­˜jsonæ–‡ä»¶
        json.dump(self.data_coco, open(self.save_json_path, 'w'),
                  indent=4, cls=MyEncoder)  # indent=4 æ›´åŠ ç¾è§‚æ˜¾ç¤º


# labelme_json = glob.glob(
#     '/home/lry/projects/mmdetection/data/780b/*.json')
# print(labelme_json)


# # labelme_json=['./Annotations/*.json']
# # labelme_json=glob.glob('./Annotations/*.json')

# saveme_json = '/home/lry/projects/mmdetection/lry/draft.json'
# print("Start.")

# labelme2coco(labelme_json, saveme_json)
# print("Finished.")


val_json = glob.glob('/home/lry/data/780b_std/val/*.json')
print(val_json)
saveme_json = '/home/lry/data/780b_std/val/annotation_coco.json'
print("Start.")

labelme2coco(val_json, saveme_json)
print("Finished.")

train_json = glob.glob('/home/lry/data/780b_std/train/*.json')
print(train_json)
saveme_json = '/home/lry/data/780b_std/train/annotation_coco.json'
print("Start.")

labelme2coco(train_json, saveme_json)
print("Finished.")
```

## åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
è¿™é‡ŒæŒ‰ç…§7ï¼š3æ¥åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†:
```python
"""æœ¬æ¨¡å—ç”¨äºåˆ’åˆ†éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œå¤§æ¦‚æ¯”ä¾‹ä¸º7ï¼š3"""

import shutil
import os
import random
import glob

def move_file(old_path, imgs,  new_path):
    '''è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥ç§»åŠ¨å›¾ç‰‡å’Œç›¸åº”çš„jsonæ–‡ä»¶'''
    print(old_path)
    print(new_path)
    # filelist = os.listdir(old_path) #åˆ—å‡ºè¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶,listdirè¿”å›çš„æ–‡ä»¶åˆ—è¡¨æ˜¯ä¸åŒ…å«è·¯å¾„çš„ã€‚
    filelist = imgs
    print(filelist)
    for file in filelist:
        # file = file - "/home/lry/data/780b_std/"
        src = os.path.join(old_path, file[len("/home/lry/data/780b_std/"):])
        dst = os.path.join(new_path, file[len("/home/lry/data/780b_std/"):])
        src_json = os.path.join(old_path, file[len("/home/lry/data/780b_std/"):-5] + '.jpg')
        dst_json = os.path.join(new_path, file[len("/home/lry/data/780b_std/"):-5] + '.jpg')
        print('src:', src)
        print('dst:', dst)
        shutil.move(src, dst)
        shutil.move(src_json, dst_json)


old_path = "/home/lry/data/780b_std"

new_val = "/home/lry/data/780b_std/val"
new_train = "/home/lry/data/780b_std/train"

pics = glob.glob("/home/lry/data/780b_std/*.json")
# print(len(pics))
# print(pics[0][len("/home/lry/data/780b_std/"):-5] + ".jpg")
# print(pics[0][:-4])
# print(pics)

print("moving....")
move_file(old_path, pics[:140], new_train)
print("train end!")

print("moving...")
move_file(old_path, pics[140:], new_val)
print("val end!")
```

## è®¾å®šconfigæ–‡ä»¶
æˆ‘ä»¬å†³å®šç”¨mask_rcnnï¼Œè¿™é‡Œç›´æ¥åœ¨`configs`ç›®å½•ä¸‹åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹å«åšfenghuoï¼Œç„¶ååŠ å…¥ä¸€ä¸ª`mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py`æ–‡ä»¶å°±OKã€‚æ–‡ä»¶å†…å®¹ä¸ºï¼š
```python
"""æœ¬æ¨¡å—ç”¨äºæ”¾ç½®configsï¼Œå®šä¹‰æ¨¡å‹ç»“æ„,
è¯¥é…ç½®æ–‡ä»¶å°†æ”¾åˆ°`/home/lry/projects/mmdetection/configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_balloon.py`"""

# The new config inherits a base config to highlight the necessary modification
_base_ = '../mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'

# We also need to change the num_classes in head to match the dataset's annotation
model = dict(
    roi_head=dict(
        bbox_head=dict(num_classes=1),
        mask_head=dict(num_classes=1)))

# Modify dataset related settings
dataset_type = 'COCODataset'
classes = ('780B',)
data = dict(
    train=dict(
        img_prefix='/home/lry/projects/mmdetection/data/780b_std/train/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/780b_std/train/annotation_coco.json'),
    val=dict(
        img_prefix='/home/lry/projects/mmdetection/data/780b_std/val/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/780b_std/val/annotation_coco.json'),
    test=dict(
        img_prefix='/home/lry/projects/mmdetection/data/780b_std/val/',
        classes=classes,
        ann_file='/home/lry/projects/mmdetection/data/780b_std/val/annotation_coco.json'))

# We can use the pre-trained Mask RCNN model to obtain higher performance
load_from = 'checkpoints/mask_rcnn_r50_caffe_fpn_mstrain-poly_3x_coco_bbox_mAP-0.408__segm_mAP-0.37_20200504_163245-42aa3d00.pth'
```
## è®­ç»ƒæ¨¡å‹
```python
python tools/train.py configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py
```

## æµ‹è¯•æ¨¡å‹
```python
CUDA_VISIBLE=1 python tools/test.py configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo/latest.pth  --eval bbox segm
```



# 2021.11.14æ—¥æ—©æ›´æ–°

* è¿œç¨‹ä»“åº“ï¼šhttps://www.jianshu.com/p/e4bb2ac7e770

ç›®å‰éœ€è¦æ–°å»ºè¿œç¨‹GitHubä»“åº“æ–¹ä¾¿æˆ‘ä¸åˆ«äººåä½œ

ç›®å‰æ•´ä¸ªå¤§æ¡†çš„æ£€æµ‹è¿˜æ¯”è¾ƒæˆåŠŸï¼Œæ¥ç€å°±æ˜¯æ£€æµ‹æ¯ä¸ªå°æ¡†çš„åˆ†ç±»ä»»åŠ¡ã€‚



# 2021.11.29æ—¥æ™šæ›´æ–°
è¿œç¨‹ä»“åº“åˆ›å»ºæˆåŠŸï¼Œä»“åº“åœ°å€ï¼š[çƒ½ç«æ£€æµ‹](https://github.com/LRY89757/mmdet-for-fenghuo)

ç›®å‰éœ€è¦åšçš„äº‹æƒ…ï¼š
* å†™ä¸€ä¸ªå…³äºè¿™ç±»Labelmeæ–‡æ¡£éœ€è¦çš„dataloaderï¼Œå†™ä¸€ä¸ªå°½é‡æ¯”è¾ƒå…¨é¢é€‚é…æ€§æ¯”è¾ƒå¼ºã€å¯è¿ç§»æ€§æ¯”è¾ƒå¥½çš„dataloader
* å¯¹äºè¿è¡Œå‡ºæ¥çš„ç»“æœçš„å›¾åƒåšä¸€ä¸ªç®€å•çš„åˆ‡åˆ†ï¼Œå¹³å‡åˆ†ä¸º19ä»½ç„¶åå°†æ¯ä¸€ä¸ªå•ç‹¬çš„ç›˜éƒ½cropå‡ºæ¥ç„¶åå°†éç›˜åŒºåŸŸæ ‡é»‘æ”¾åˆ°resnet101ç­‰å„ç±»åˆ†ç±»ç½‘ç»œä¸­è¿›è¡Œç›¸å…³çš„åˆ†ç±»ä»»åŠ¡ã€‚
* åˆ’åˆ†æµ‹è¯•é›†å’Œè®­ç»ƒé›†çš„æ—¶å€™é€‰æ‹©ä½¿ç”¨ç”Ÿæˆval.txtè¿˜æœ‰train.txtæ–‡ä»¶çš„æ ¼å¼ï¼Œæ¯ä¸ª.txtæ–‡ä»¶å†…é˜²æ­¢ç›¸å…³æ•°æ®çš„è·¯å¾„ã€‚è€Œä¸æ˜¯å°†å…¶å¤åˆ¶åˆ°ä¸€ä¸ªæ–°çš„æ–‡ä»¶å¤¹ä¸­è¿›è¡Œåˆ†ç±»ï¼Œä¸‡ä¸€ç¡¬ç›˜æ²¡æœ‰é‚£ä¹ˆå¤§çš„ç©ºé—´æ€ä¹ˆåŠï¼Œä¸è¦æ»¥ç”¨ç¡¬ç›˜èµ„æºã€‚



# 2021.11.30æ—¥æ™šæ›´æ–°
ç›®å‰å·²ç»ç¡®å®šæœ¬å‘¨å…ˆåšç¬¬äºŒé¡¹ï¼Œå°±æ˜¯åšä¸€ä¸‹ç›®å‰ç›˜ç¬¦çš„åˆ†ç±»æ“ä½œã€‚
ï¼ˆå®é™…ä¸Šç›®å‰è¿™ä¸ªä»»åŠ¡çš„ä¸»è¦æ­¥éª¤ä¹‹ç±»çš„è¿˜ä¸æ˜¯ç‰¹åˆ«æ¸…æ™°ï¼Œè¿˜æ˜¯éœ€è¦è¿›ä¸€æ­¥ä¸ç»„é•¿è®¨è®ºäº¤æµï¼Œä¸è¿‡å…³äºcv2çš„ä¸€äº›æ“ä½œè¿™ç±»å¯ä»¥è‡ªå·±å…ˆå­¦ä¸€å­¦ï¼Œåæ­£å…·ä½“çš„å†…å®¹çŸ¥é“äº†ï¼Œæ›´å…·ä½“çš„ç»†èŠ‚è¿˜æ²¡æ²Ÿé€šå¥½ã€‚ï¼‰



## The result of `inference_detector()`

ç›®å‰ç¬¬ä¸€æ­¥é‡åˆ°çš„å›°éš¾å°±æ˜¯æš‚æ—¶ä¸çŸ¥é“æˆ‘ä»¬`inference_detector()`è¿™ä¸ªå‡½æ•°å¾—åˆ°çš„ç»“æœçš„å¤§è‡´å½¢å¼ã€‚å› ä¸ºä¹‹å‰åšåˆ†å‰²çš„æ—¶å€™ç›´æ¥å°†ç»“æœæ”¾åˆ°å‡½æ•°çš„å‚æ•°ä¸­`model.show_result(img, result, out_file=f'/home/lry/projects/mmdetection/lry/demo{i}.jpg')`æ¥æ˜¾ç¤ºç»“æœäº†ï¼Œå†åŠ ä¸Šæˆ‘æœ¬æ¥å¯¹è¿™ä¸ªä¹Ÿä¸å¤ªç†Ÿæ‚‰ï¼Œæ‰€ä»¥ç›®å‰æ‰“ç®—æ·±å…¥ç†è§£ä¸‹å…³äºå‡½æ•°`inference_detector()`ï¼Œé¡ºä¾¿å°†è¿™ä¸€ç³»åˆ—æœ‰å…³çš„éƒ½äº†è§£ä¸€ä¸‹ï¼š`init_detector,inference_detector, show_result_pyplot`,è¿™äº›éƒ½æ˜¯æºäºåº“`mmdet.apis`,æ‰€ä»¥æˆ‘ä»¬æ¥æ‰¾ä¸€ä¸‹[å®˜æ–¹æ–‡æ¡£](https://mmdetection.readthedocs.io/en/latest/api.html)å…³äºmmdet.apisçš„æœ‰å…³è§£é‡Šï¼š
å®é™…ä¸Šæœ‰å…³`inference_detector`çš„[å†…å®¹](https://mmdetection.readthedocs.io/en/latest/api.html#mmdet.apis.inference_detector)ååˆ†æœ‰é™ï¼š

> mmdet.apis.inference_detector(*model*, *imgs*)[[SOURCE\]](https://mmdetection.readthedocs.io/en/latest/_modules/mmdet/apis/inference.html#inference_detector)
>
> Inference image(s) with the detector.
>
> - Parameters
>
>   **model** (*nn.Module*) â€“ The loaded detector.**imgs** (*str/ndarray* *or* *list**[**str/ndarray**] or* *tuple**[**str/ndarray**]*) â€“ Either image files or loaded images.
>
> - Returns
>
>   If imgs is a list or tuple, the same length list type results will be returned, otherwise return the detection results directly.

å½“ç„¶æ„Ÿå…´è¶£å¯ä»¥å»é€‰æ‹©çœ‹ä¸€ä¸‹æœ‰å…³æºç .è¿™é‡Œæˆ‘é€‰æ‹©ç”¨ä»£ç æ¥æ¢ç´¢ä¸‹æœ‰å…³çš„ç»“æœ:
```python
from mmdet.apis import init_detector,inference_detector, show_result_pyplot
import mmcv
import os
import glob
from PIL import Image
from torchvision.transforms import ToTensor

config_file = "/home/lry/projects/mmdetection/configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py"
checkpoint_file = "/home/lry/projects/mmdetection/work_dirs/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo/latest.pth"
model = init_detector(config_file, checkpoint_file,device="cuda:3")

img = '/home/lry/projects/mmdetection/data/780b_std/IMG_20211021_153945.jpg'
result = inference_detector(model, img)
print(result, '\n\n', result[0], '\n\n', result[0][0])
print(result[1][0][0].shape)
img = Image.open(img)
print(ToTensor()(img).shape)

```

æœ‰å…³è¿™éƒ¨åˆ†ä¸»è¦å°±çœ‹resultçš„è¾“å‡ºåˆ°åº•æ˜¯ä»€ä¹ˆä¸œè¥¿,å¦‚æœæˆ‘ä»¬æƒ³è¦ä¿å­˜ç»“æœåˆ°æŸåœ°æˆ–æ˜¯å±•ç¤ºç»“æœå¯ä»¥ç”¨`model.show_result(img, result, out_file=f'/home/lry/projects/mmdetection/lry/demo{i}.jpg')`æ¥æ˜¾ç¤º.

ç®€å•æ¥çœ‹ä¸‹ä»£ç è¿è¡Œç»“æœ:
```python
([array([[3.6979218e+02, 2.3255410e+03, 2.7979324e+03, 4.2280156e+03,
        9.9831665e-01]], dtype=float32)], [[array([[False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       ...,
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False],
       [False, False, False, ..., False, False, False]])]]) 

 [array([[3.6979218e+02, 2.3255410e+03, 2.7979324e+03, 4.2280156e+03,
        9.9831665e-01]], dtype=float32)] 

 [[3.6979218e+02 2.3255410e+03 2.7979324e+03 4.2280156e+03 9.9831665e-01]]
(4608, 3456)
torch.Size([3, 4608, 3456])
```
å¯ä»¥çœ‹åˆ°,resultæ˜¯ä¸€ä¸ªå…ƒç»„,å…ƒç»„çš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªnp.array,å«æœ‰5ä¸ªå…ƒç´ ,5ä¸ªå…ƒç´ ä¸­ç¬¬ä¸€ä¸ªä»£è¡¨çš„æ˜¯æ£€æµ‹æ¡†çš„å‡†ç¡®åº¦,ç„¶åå››ä¸ªå‚æ•°ä»£è¡¨çš„æ˜¯å›¾ç‰‡çš„æ£€æµ‹æ¡†çš„å·¦ä¸Šå³ä¸‹ç›¸å…³å‚æ•°,ç„¶åç¬¬äºŒä¸ªå…ƒç´ å°±æ˜¯å›¾ç‰‡åˆ†å‰²æ•°æ®é›†çš„åˆ†å‰²ç»“æœäº†.è¿™ä¸ªç»“æœæ˜¯ç”±Trueå’ŒFalseç»„æˆçš„å’Œå›¾åƒæœ¬èº«Tensorå¤§å°ç›¸åŒçš„ä¸€ä¸ªçŸ©é˜µ.(Trueä»£è¡¨è¯¥åƒç´ æ˜¯å«æœ‰ç‰©ä½“çš„)ã€‚

## Code Trace of `mmdet.apis.inference_detector()`
çš„ç¡®åˆšæ‰æˆ‘ä»¬å°†è¿™ä¸ªæ¥å£å½“ä½œé»‘ç›’æ¥æ¢ç´¢åˆ°äº†ä»–çš„ä¸€äº›å…·ä½“åŠŸèƒ½ã€‚è¿™æ ·å¯¹äºåšé¡¹ç›®æ¥è¯´éå¸¸è¶³å¤Ÿäº†ï¼Œä½†æ˜¯æˆ‘ä»¬è¿™é‡Œæ·±å…¥ä¸€ä¸‹æ¥æ¢ç´¢ä¸€ä¸‹ä»–çš„æºç æ˜¯æ€ä¹ˆæ ·çš„ï¼ˆ~~æ„Ÿè°¢è’‹å“¥å¸¦æˆ‘é£~~ï¼‰ã€‚

é¦–å…ˆæ¥çœ‹æˆ‘ä»¬çš„inference_detector()æºç `mmdet/apis/inference.py`:
```python
def inference_detector(model, imgs):
    """Inference image(s) with the detector.

    Args:
        model (nn.Module): The loaded detector.
        imgs (str/ndarray or list[str/ndarray] or tuple[str/ndarray]):
           Either image files or loaded images.

    Returns:
        If imgs is a list or tuple, the same length list type results
        will be returned, otherwise return the detection results directly.
    """

    if isinstance(imgs, (list, tuple)):
        is_batch = True
    else:
        imgs = [imgs]
        is_batch = False

    cfg = model.cfg
    device = next(model.parameters()).device  # model device

    if isinstance(imgs[0], np.ndarray):
        cfg = cfg.copy()
        # set loading pipeline type
        cfg.data.test.pipeline[0].type = 'LoadImageFromWebcam'

    cfg.data.test.pipeline = replace_ImageToTensor(cfg.data.test.pipeline)
    test_pipeline = Compose(cfg.data.test.pipeline)

    datas = []
    for img in imgs:
        # prepare data
        if isinstance(img, np.ndarray):
            # directly add img
            data = dict(img=img)
        else:
            # add information into dict
            data = dict(img_info=dict(filename=img), img_prefix=None)
        # build the data pipeline
        data = test_pipeline(data)
        datas.append(data)

    data = collate(datas, samples_per_gpu=len(imgs))
    # just get the actual data from DataContainer
    data['img_metas'] = [img_metas.data[0] for img_metas in data['img_metas']]
    data['img'] = [img.data[0] for img in data['img']]
    if next(model.parameters()).is_cuda:
        # scatter to specified GPU
        data = scatter(data, [device])[0]
    else:
        for m in model.modules():
            assert not isinstance(
                m, RoIPool
            ), 'CPU inference with RoIPool is not supported currently.'

    # forward the model
    with torch.no_grad():
        results = model(return_loss=False, rescale=True, **data)

    if not is_batch:
        return results[0]
    else:
        return results
```

å®é™…ä¸Šè¿™ä¹ˆé•¿çš„æºç ï¼ŒçœŸæ­£å…³é”®çš„å°±å€’æ•°ç¬¬å…­è¡Œçš„ä»£ç `results = model(return_loss=False, rescale=True, **data)`è¿™è¡Œä»£ç è°ƒç”¨äº†modelæ¥è¿›è¡Œæ¨ç†ç„¶åè¿”å›äº†ç»“æœresultsã€‚æˆ‘ä»¬è¦çœ‹modelçš„è€Œmodelæ˜¯æˆ‘ä»¬ä¼ è¿›æ¥çš„å‚æ•°ï¼Œæ˜¯æˆ‘ä»¬ä½¿ç”¨`init_detector`è¿™ä¸ªæ¥å£æ¥è°ƒç”¨çš„ï¼Œè¿™ä¸ªæ¥å£ä½¿ç”¨äº†æˆ‘ä»¬çš„configæ–‡ä»¶ä»¥åŠç›¸å…³çš„checkpointæ–‡ä»¶ã€‚è¿™é‡Œconfigæ–‡ä»¶å·²ç»éå¸¸ç†Ÿæ‚‰äº†ï¼Œå°±æ˜¯åˆ©ç”¨è¿™ä¸ªæ­å»ºçš„æ¨¡å‹ã€‚æˆ‘ä»¬éœ€è¦çœ‹çš„æ˜¯å…³äºconfigæ–‡ä»¶é‡Œé¢æ‰€ç”¨çš„æ¨¡å‹ã€‚è€Œè¦æœ€åçš„è¾“å‡ºæ˜¯ç”±`roi_heads`ï¼Œä¹Ÿå°±æ˜¯maskrcnnæœ€åä¸€ä¸ªæ¨¡å—æ¥è¾“å‡ºçš„ã€‚æˆ‘ä»¬å…ˆè¿½è¸ªä¸€ä¸‹æœ‰å…³çš„configæ–‡ä»¶ï¼š
é¦–å…ˆæ˜¯æˆ‘ä»¬è‡ªå·±å®šä¹‰çš„ä¸Šå±‚çš„configæ–‡ä»¶`configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py`, ä»è¿™é‡Œæ‰¾å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ç»§æ‰¿çš„æ˜¯`_base_ = '../mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'`é‚£ä¹ˆæˆ‘ä»¬ç»§ç»­æ‰¾åˆ°è¿™ä¸ªæ¨¡å—å°±`configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py`,å¯ä»¥çœ‹åˆ°ä»–ç»§æ‰¿çš„æ˜¯`_base_ = './mask_rcnn_r50_fpn_1x_coco.py'`,æˆ‘ä»¬ç»§ç»­æ‰¾è¿™ä¸ªæ–‡ä»¶`configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py`,è¿™ä¸ªæ–‡ä»¶æœ‰ç‚¹åƒæ˜¯ä¸€ä¸ªpackageçš„`__init__.py`ï¼Œå°±æ˜¯ä»£ç åªæœ‰æ‰€æœ‰éœ€è¦ç»§æ‰¿çš„åŸºæœ¬ç±»å‹ï¼š
```python
_base_ = [
    '../_base_/models/mask_rcnn_r50_fpn.py',
    '../_base_/datasets/coco_instance.py',
    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'
]
```
è¿™é‡Œå°±æ˜¯ä¸€äº›æ¨¡å‹å…·ä½“é…ç½®çš„ç»§æ‰¿åŸºç±»æ–‡ä»¶ï¼Œæˆ‘ä»¬æƒ³è¦çœ‹æ¨¡å‹çš„`roi_heads`éƒ¨åˆ†ï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å»æ‰¾`'../_base_/models/mask_rcnn_r50_fpn.py'`æ–‡ä»¶ã€‚æˆ‘ä»¬å¯ä»¥åœ¨`configs/_base_/models/mask_rcnn_r50_fpn.py`é‡Œæ‰¾åˆ°`roi_heads`çš„å®šä¹‰:
```python
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=80,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0., 0., 0., 0.],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
        mask_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        mask_head=dict(
            type='FCNMaskHead',
            num_convs=4,
            in_channels=256,
            conv_out_channels=256,
            num_classes=80,
            loss_mask=dict(
                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),
```
è¿™é‡Œé¢å¯ä»¥çœ‹åˆ°æ•´ä¸ª`roi_head`éƒ½æ˜¯å±äº`type='StandardRoIHead'`, ç”±äºMMDetectionçš„æ³¨å†Œå™¨Registryæœºåˆ¶ï¼Œæˆ‘ä»¬çŸ¥é“æˆ‘ä»¬éœ€è¦å»åˆ°`mmdet`æ–‡ä»¶å¤¹ä¸­å»æ‰¾è¿™äº›ä¸œè¥¿ï¼Œåœ¨`mmdet/models/roi_heads`ä¸­æˆ‘ä»¬å¯ä»¥æ‰¾åˆ°`mmdet/models/roi_heads/standard_roi_head.py`è¿™ä¸ªæ–‡ä»¶ã€‚
ç„¶åæˆ‘ä»¬éœ€è¦ä»ç±»ä¸­å¯»æ‰¾å…³äºforwardçš„æœ‰å…³å‡½æ•°ï¼Œåˆšå¼€å§‹æ‰¾çš„æ˜¯`forward_dummy()`è¿™ä¸ªå‡½æ•°ï¼Œä½†æ˜¯ä»è¿™ä¸ªå‡½æ•°ä¸­çœ‹ä¸åˆ°å…³äºcls_scoreå’Œbbox_predä»¥åŠmask_predçš„åˆå¹¶æœ‰å…³æ­¥éª¤ï¼Œæˆ–è€…è¯´ä¸å¤ªèƒ½å¯¹åº”ä¸Šï¼Œåæ¥æ‰“äº†ä¸€äº›æ–­ç‚¹å‘ç°ä¼¼ä¹ç¨‹åºæ ¹æœ¬ä¸ä¼šç»è¿‡è¿™ä¸ªå‡½æ•°ã€‚æ‰€ä»¥åº”è¯¥ä¸æ˜¯ç»è¿‡è¿™ä¸ªforwardå‡½æ•°ï¼Œè€Œå¦å¤–çš„forwardå‡½æ•°ï¼Œé¦–å…ˆå¯ä»¥æ’é™¤`forward_train`è¿™ä¸ªå‡½æ•°ï¼Œæˆ–è€…æ˜¯æ’é™¤æ‰€æœ‰å’Œtrainæœ‰å…³çš„å‡½æ•°ï¼Œå› ä¸ºæˆ‘ä»¬æ¯•ç«Ÿè¿™ä¸ªæ˜¯åšçš„æ¨æ–­ï¼Œæ‰€ä»¥æˆ‘ä»¬éœ€è¦çš„ä¸æ˜¯å»trainï¼Œè‡³å°‘ä¹Ÿåœ¨testé‡Œé¢ã€‚

åæ¥ç»è¿‡æ‰“æ–­ç‚¹å‘ç°ç¨‹åºè¿è¡Œåœ¨`simple_test()`è¿™ä¸ªå‡½æ•°é‡Œé¢ï¼š
```python
    def simple_test(self,
                    x,
                    proposal_list,
                    img_metas,
                    proposals=None,
                    rescale=False):
        """Test without augmentation.

        Args:
            x (tuple[Tensor]): Features from upstream network. Each
                has shape (batch_size, c, h, w).
            proposal_list (list(Tensor)): Proposals from rpn head.
                Each has shape (num_proposals, 5), last dimension
                5 represent (x1, y1, x2, y2, score).
            img_metas (list[dict]): Meta information of images.
            rescale (bool): Whether to rescale the results to
                the original image. Default: True.

        Returns:
            list[list[np.ndarray]] or list[tuple]: When no mask branch,
            it is bbox results of each image and classes with type
            `list[list[np.ndarray]]`. The outer list
            corresponds to each image. The inner list
            corresponds to each class. When the model has mask branch,
            it contains bbox results and mask results.
            The outer list corresponds to each image, and first element
            of tuple is bbox results, second element is mask results.
        """
        assert self.with_bbox, 'Bbox head must be implemented.'

        det_bboxes, det_labels = self.simple_test_bboxes(
            x, img_metas, proposal_list, self.test_cfg, rescale=rescale)

        bbox_results = [
            bbox2result(det_bboxes[i], det_labels[i],
                        self.bbox_head.num_classes)
            for i in range(len(det_bboxes))
        ]

        if not self.with_mask:
            return bbox_results
        else:
            segm_results = self.simple_test_mask(
                x, img_metas, det_bboxes, det_labels, rescale=rescale)
            return list(zip(bbox_results, segm_results))
```

æ¥ç€è°ƒè¯•å‘ç°è¿™é‡Œè°ƒç”¨äº†å‡½æ•°bbox2result()æ¥å®ç°äº†å…³äºè½¬åŒ–çš„ä¸€äº›é—®é¢˜ã€‚

å®é™…ä¸Šåˆ°æ­¤å°±ç»“æŸäº†ï¼Œå½“ç„¶`forward_dummy()`è¿™ä¸ªå‡½æ•°æ˜¯éå¸¸æœ‰ç ”ç©¶æ„ä¹‰çš„ï¼Œåœ¨`mmdet/models/detectors/two_stage.py`é‡Œå¯ä»¥çœ‹åˆ°è¿™ä¸ªæ˜¯ä¸ºäº†ï¼Œç‰¹åˆ«æ˜¯è¿™é‡Œè°ƒç”¨äº†`_bbox_forward()`è¿™ä¸ªå‡½æ•°,å€¼å¾—æ³¨æ„ä¸€ä¸‹ã€‚


å¦å¤–æˆ‘ä»¬ä»¥ä¸Šä»…ä»…æ˜¯è®²äº†ä¸€ä¸ªmask_rcnnçš„ä¸€ä¸ªå¾ˆå°çš„`roi_head`éƒ¨åˆ†ï¼Œå¦‚æœè¦æ€»ä½“çœ‹å…¨ä½“çš„ä¸€ä¸ªæ¦‚å†µçš„è¯ï¼Œå¯ä»¥é€‰æ‹©å»çœ‹ä¸€ä¸‹`mmdet/models/detectors/two_stage.py`è™½ç„¶ä¹Ÿä¸ç®—æ˜¯æ€»ä½“ï¼Œä½†æ˜¯ä¹Ÿé«˜äº†ä¸€çº§ï¼Œå¯ä»¥çœ‹ä¸€ä¸‹å…·ä½“çš„è¿™ä¸ª`TwoStageDetector`æ˜¯æ€ä¹ˆè°ƒåº¦çš„ï¼Œæ˜¯å¦‚ä½•è¿è¡Œèµ·æ¥çš„ã€‚




## dataloader in mmdetection

å…¶æ¬¡æ˜¯å…³äºè¿™å‘¨è¦åšçš„ç¬¬ä¸€ä¸ªä»»åŠ¡ï¼Œè¿™ä¸ªä»»åŠ¡å®é™…ä¸Šå°±æ˜¯æ¥åšä¸€ä¸ªLabelmeæ•°æ®çš„dataloader,å½“ç„¶è¯´èµ·æ¥å®¹æ˜“ï¼Œè¿™ä¸ªè¦æŠŠdataloaderèåˆ°MMDetectioné‡Œé¢è¿˜æ˜¯éœ€è¦æ·±å…¥ç†è§£ä»–çš„Rigistryæœºåˆ¶çš„ï¼Œè€Œä¸”å…‰å†™ä»£ç è¿™ä¸€æ­¥å¦‚æœå®Œå…¨ä¸çœ‹ä»–çš„å…³äºCOCODatasetçš„ä»£ç é è‡ªå·±å†™ææ€•æ˜¯éå¸¸éš¾åŠçš„ã€‚æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œä¸€æ­¥ä¸€æ­¥çš„æ¥æ¢ç´¢ã€‚

é¦–å…ˆæˆ‘ä»¬æ¥æ‰¾åˆ°COCOçš„dataloaderåˆ°åº•åœ¨å“ªé‡Œã€‚

è¿˜æ˜¯ä»configæ–‡ä»¶å¼€å§‹æ‰¾ï¼Œç”±äºä¸Šæ–‡å·²ç»æ‰¾è¿‡äº†ï¼Œè¿™é‡Œç›´æ¥å¼•ç”¨ä¸Šæ–‡çš„å¯»æ‰¾è¿‡ç¨‹ï¼š


""""
é¦–å…ˆæ˜¯æˆ‘ä»¬è‡ªå·±å®šä¹‰çš„ä¸Šå±‚çš„configæ–‡ä»¶`configs/fenghuo/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_fenghuo.py`, ä»è¿™é‡Œæ‰¾å¯ä»¥çœ‹åˆ°æˆ‘ä»¬ç»§æ‰¿çš„æ˜¯`_base_ = '../mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py'`é‚£ä¹ˆæˆ‘ä»¬ç»§ç»­æ‰¾åˆ°è¿™ä¸ªæ¨¡å—å°±`configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py`,å¯ä»¥çœ‹åˆ°ä»–ç»§æ‰¿çš„æ˜¯`_base_ = './mask_rcnn_r50_fpn_1x_coco.py'`,æˆ‘ä»¬ç»§ç»­æ‰¾è¿™ä¸ªæ–‡ä»¶`configs/mask_rcnn/mask_rcnn_r50_fpn_1x_coco.py`,è¿™ä¸ªæ–‡ä»¶æœ‰ç‚¹åƒæ˜¯ä¸€ä¸ªpackageçš„`__init__.py`ï¼Œå°±æ˜¯ä»£ç åªæœ‰æ‰€æœ‰éœ€è¦ç»§æ‰¿çš„åŸºæœ¬ç±»å‹ï¼š
```python
_base_ = [
    '../_base_/models/mask_rcnn_r50_fpn.py',
    '../_base_/datasets/coco_instance.py',
    '../_base_/schedules/schedule_1x.py', '../_base_/default_runtime.py'
]
```
"""

ç„¶åæˆ‘ä»¬å¯ä»¥çœ‹åˆ°åœ¨`'../_base_/datasets/coco_instance.py'`é‡Œé¢ï¼Œå‰å‡ è¡Œä»£ç å°±æœ‰`dataset_type = 'CocoDataset'`å’Œä¸Šæ–‡ç›¸åŒçš„Registryæœºåˆ¶ï¼Œæˆ‘ä»¬åˆ°`mmdet`æ–‡ä»¶å¤¹ä¸­å»å¯»æ‰¾ï¼Œå¯ä»¥å‘ç°åœ¨`mmdet/datasets/coco.py`é‡Œé¢æœ‰`CocoDataset`è¿™ä¸ªç±»ã€‚è¿™ä¸ªå°±æ˜¯å…³äºCocoDatasetçš„dataloader.ç»ˆäºæ‰¾åˆ°äº†ï¼

ä½†æ˜¯æœ‰574è¡Œä»£ç â€¦â€¦â€¦â€¦â€¦â€¦â€¦â€¦èšŒåŸ ä½äº†ğŸ˜¥ã€‚

# 2021.12.1æ—¥ä¸Šåˆæ›´æ–°

## dataloader in mmdet
å†ç¨å¾®è¯´ä¸€ä¸‹å…³äºRigistryè¿˜æœ‰ç»§æ‰¿ç±»éœ€è¦åšçš„ä¸€äº›ä¸œè¥¿ã€‚

## å›¾åƒåˆ†å‰²ç›˜ç¬¦åˆ‡ç‰‡æ•°æ®é¢„å¤„ç†æ“ä½œ

### Preface
æ˜¨å¤©æœ¬æ¥æ‰“ç®—è®¤çœŸåšä¸€ä¸‹å…³äºç›˜ç¬¦åˆ†ç±»çš„ä»»åŠ¡çš„ï¼Œæ²¡æƒ³åˆ°è¿˜æ˜¯æœ€ç»ˆæ²¡æœ‰å¼„ï¼Œå…‰é¡¾ç€æMMdetectionçš„æºç è¿™äº›ä¸œè¥¿äº†æ²¡æœ‰æ¥å¾—åŠæï¼Œç›®å‰å·²çŸ¥æ¥å£`inference_detector`è¿”å›çš„resultçš„ç»“æœäº†ï¼Œå°±æ˜¯ä¸€ä¸ªå…ƒç»„tupleï¼Œç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æ£€æµ‹æ¡†çš„ä½ç½®å’Œç½®ä¿¡åº¦ï¼Œç„¶åç¬¬äºŒä¸ªå…ƒç´ å°±æ˜¯åˆ†å‰²çš„ç»“æœï¼Œæ˜¯ä¸€ä¸ªä¸å›¾ç‰‡å¤§å°ç›¸åŒçš„ä¸€ä¸ªäºŒç»´çŸ©é˜µï¼Œç”±Trueå’ŒFalseç»„æˆã€‚

æˆ‘ä»¬æ¥ä¸‹æ¥å¼€å§‹å°è¯•åšå›¾åƒçš„å¤„ç†ã€‚

é¦–å…ˆæ„å»ºdetectorå¾—åˆ°ä¸€äº›å…·ä½“ç»“æœï¼š
![](https://s6.jpg.cm/2021/12/01/LqL6m6.png)

### å›¾åƒå¤„ç†ç®—æ³•åˆ†æä¸ç®—æ³•æ­¥éª¤å®ç°


#### å¯¹äºåˆ†å‰²çš„ç»“æœé¢„å¤„ç†
é¦–å…ˆï¼Œè¿™ä¸ªæ£€æµ‹æ¡†çš„ç»“æœå¹¶ä¸æ˜¯éå¸¸é è°±,å¾ˆæ˜æ˜¾å¦‚æœæˆ‘ä»¬é€‰æ‹©å¯¹å¾—åˆ°çš„bboxæ¥è¿›è¡Œå‡ç­‰åˆ†å‰²æ˜¯å®Œå…¨ä¸è¡Œçš„ï¼Œåˆ†å‰²çš„ç»“æœè¿˜è¦å¥½ä¸€äº›ç›¸å¯¹è€Œè¨€ï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™é‡Œå¯ä»¥é€‰æ‹©è€ƒè™‘ä¸€ä¸‹ä½¿ç”¨åˆ†å‰²æ•°æ®ä½†æ˜¯è¦å¯¹åˆ†å‰²æ•°æ®è¿›è¡Œä¸€äº›è½¬æ¢æˆ–è€…æ˜¯è¯´ä¿®è¡¥ã€‚

ç›®å‰ä¸€ä¸ªæƒ³æ³•æ˜¯å¯¹äºåˆ†å‰²ç»“æœçš„è¾¹ç•Œå–å¹³å‡å€¼æ¥å¾—åˆ°4æ¡å¯ä»¥ç”¨çš„è¾¹ç»„æˆä¸€ä¸ªæ–°çš„bboxã€‚ç„¶åæˆ‘ä»¬å†å¯¹å¾—åˆ°çš„æ–°çš„bboxè¿›è¡Œå¹³å‡åˆ‡åˆ†æˆ19ç­‰ä»½ï¼Œå½“ç„¶è¿™é‡Œæ²¡æœ‰è€ƒè™‘æ˜¯å¦æ˜¯å€¾æ–œçš„ï¼Œå› ä¸ºæˆ‘ä»¬è¦åˆ‡å‡ºçš„å›¾ç‰‡è¦éƒ½æ˜¯æ°´å¹³çŸ©å½¢ï¼Œç„¶åæ ¹æ®åæ ‡å…³ç³»å°†æˆ‘ä»¬åˆ‡é™¤çŸ©å½¢éƒ¨åˆ†ä¸åŒ…å«ç›˜ç¬¦çš„éƒ¨åˆ†æ¶‚é»‘ï¼ˆæ‰€ä»¥å†™ä»£ç æ—¶ä¸å¦¨å…ˆå°†éç›˜ç¬¦éƒ¨åˆ†æ¶‚é»‘ã€‚ï¼‰

ç›®å‰è€ƒè™‘çš„ç®—æ³•æ­¥éª¤æ˜¯ï¼š
* æ ¹æ®æ„å»ºdetectorå¾—åˆ°çš„åˆ†å‰²ç»“æœçŸ©é˜µï¼Œæ ¹æ®è¾¹ç•Œå¹³å‡æ€æƒ³å¾—åˆ°ä¸€ä¸ª bbox
* å¾—åˆ°bboxçš„å››ä¸ªé¡¶ç‚¹ï¼ˆä¸€å®šæ˜¯bboxçŸ©é˜µæœ€é å·¦ï¼Œæœ€é å³ï¼Œæœ€é ä¸Šï¼Œæœ€é ä¸‹çš„å››ä¸ªé¡¶ç‚¹ï¼‰ã€‚
* æ ¹æ®å››ä¸ªé¡¶ç‚¹çš„å…³ç³»å¾—åˆ°å·¦å³çš„ä¸¤ç»„è¾¹çš„ç‚¹ï¼Œç„¶åæ ¹æ®å·¦å³ç­‰æ¯”ä¾‹å…³ç³»æ ‡æ³¨å¥½ä¸­é—´è¦åˆ‡åˆ†çš„18ä¸ªç‚¹ï¼Œè¿åŒç€å·¦å³ä¸¤ç«¯ç‚¹éƒ½æ”¾åˆ°ä¸€ä¸ªåˆ—è¡¨é‡Œï¼Œä¸Šä¸‹éƒ½è¦æœ‰ï¼Œï¼ˆå…¶å®ä¹Ÿå°±é€šè¿‡ç»™bboxçš„çŸ©é˜µä¸Šä¸‹ä¸¤æ¡è¾¹ç­‰åˆ†æˆ19ä»½ï¼Œä»¥åˆ©äºåç»­ç”»å›¾åˆ‡å‰²ã€‚ï¼‰
* å¼€å§‹åˆ‡å‰²ï¼Œå¹¶é€‰æ‹©å°†å›¾ç‰‡ä¸­éç›˜ç¬¦çš„éƒ¨åˆ†æ¶‚é»‘ï¼ˆè¿™ä¸ªå¯ä»¥åœ¨åˆ‡å‰²ä¹‹å‰å°±æ¶‚é»‘äº†ï¼‰
* å¯¹ä¸€å¼ å›¾ç‰‡å¾—åˆ°çš„19ä¸ªç›˜ç¬¦æ ‡ä¸Šç§ç±»ï¼Œè‡³äºç§ç±»å¯ä»¥é€‰æ‹©åˆ©ç”¨å½“æ—¶çš„jsonæ–‡ä»¶æ¥æ ‡ç§ç±»ã€‚

ç»†èŠ‚è¡¥å……ï¼š
* é¦–å…ˆé€šè¿‡å››ä¸ªé¡¶ç‚¹å¾—åˆ°ä¸€ä¸ªæ°´å¹³bboxå¯ä»¥å†™ä¸€ä¸ªå‡½æ•°å¤ç”¨
* ç»™å®šä¸¤ä¸ªé¡¶ç‚¹å°†å…¶è¿çº¿ç­‰åˆ†å‰²æˆ19ä»½å¹¶è¿”å›è¯¥ç›´çº¿æ‰€åˆ†åæ ‡åˆ—è¡¨ï¼Œæˆ–è€…è¯´ç»™å®šå››ä¸ªé¡¶ç‚¹è¿”å›åˆ‡åˆ†å¥½çš„å„ä¸ªå°ç›˜ç¬¦é¡¶ç‚¹åæ ‡åˆ—è¡¨ï¼ˆæ„æ€å°±æ˜¯åˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ éƒ½æ˜¯ä¸€ä¸ªåˆ†å¥½çš„å°æ¡†çš„å››ä¸ªé¡¶ç‚¹åæ ‡ï¼‰ã€‚
* æ¶‚é»‘æ“ä½œå®šä¹‰ä¸€ä¸ªå‡½æ•°ï¼Œè¾“å…¥ä¸º
* **ä»¥ä¸Šæ‰€æœ‰çš„æ“ä½œéƒ½æ”¾åˆ°ä¸€ä¸ªç±»é‡Œç»Ÿä¸€å¤„ç†ï¼Œç„¶ååˆ°æ—¶å€™è°ƒç”¨ç›´æ¥æ„å»ºç±»çš„æ—¶å€™å°±è°ƒç”¨äº†è¿›è¡Œå®Œé¢„å¤„ç†æ“ä½œã€‚**


#### å¯¹äºæ™®é€šæ ‡æ³¨labelmeæ–‡ä»¶çš„ç»“æœé¢„å¤„ç†

å› ä¸ºLabelmeæ–‡ä»¶æ˜¯å¯¹äºæ¯ä¸€ä¸ªå›¾ç‰‡éƒ½æœ‰ä¸€ä¸ªå•ç‹¬çš„jsonæ–‡ä»¶ï¼Œç„¶åæ¯ä¸€ä¸ªjsonæ–‡ä»¶éƒ½ä¼šæœ‰å„ä¸ªç›˜ç¬¦çš„ä½ç½®ä¿¡æ¯è¿˜æœ‰å…·ä½“çš„åæ ‡ç§ç±»ï¼Œæ‰€ä»¥è¿™æ ·ä¸€æ¥ç›¸æ¯”äºåˆ†å‰²çš„ç»“æœè¦å¥½å¾ˆå¤šï¼Œæ‰€ä»¥æˆ‘ä»¬è¿™é‡Œæ€è·¯ç®€å•å¾ˆå¤šï¼š
* è¯»å–`.json`æ–‡ä»¶
* å¯¹äºå°†æ¯ä¸ªå°ç›˜ç¬¦å››ä¸ªé¡¶ç‚¹è½¬åŒ–ä¸ºä¸€ä¸ªè¾ƒå¤§çš„bbox
* å¤§æ¡†bboxå†…éç›˜ç¬¦éƒ¨åˆ†æ¶‚é»‘
* ä¿å­˜ï¼Œæ³¨æ„å›¾ç‰‡æ ‡ç­¾çš„ä¿å­˜


### æ™®é€šlabelmeæ–‡ä»¶è¯»å–åˆ†æ



